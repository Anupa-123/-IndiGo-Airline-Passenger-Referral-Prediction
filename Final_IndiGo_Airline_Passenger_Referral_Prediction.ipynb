{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "lQ7QKXXCp7Bj",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - IndiGo Airline Passenger Referral Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name** - Anupa Devda\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The airline industry is a vital component of modern transportation, with countless airlines operating across a wide range of global routes. In such a highly competitive environment, data-driven insights are essential for informed decision-making by airlines and stakeholders. Machine learning models play a key role in this process, enabling the classification of airlines based on various criteria. This document presents the development and deployment of a machine learning model for airline classification.\n",
        "\n",
        "Machine learning proves especially useful when leveraging historical customer data to uncover patterns and relationships that suggest a high likelihood of customer referrals. Airlines can use these insights to strategically target specific customers with tailored marketing efforts or incentives, thereby increasing referral rates and driving business growth.\n",
        "\n",
        "Ultimately, a machine learning model that estimates the probability of customer referrals can deliver meaningful insights to help airlines improve customer satisfaction and expand through word-of-mouth promotion.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this machine learning project is to categorize airlines based on specific features and attributes. Such classification can serve various strategic purposes, including identifying suitable partners for codeshare agreements, informing pricing strategies, and supporting market analysis. In this project, we focus on analyzing whether passengers would recommend an airline to friends and family, based on their travel experiences, reviews, and ratings.\n",
        "\n",
        "This project addresses several key objectives and challenges:\n",
        "\n",
        "* Develop a classification model to group airlines based on the likelihood that customers will recommend them to friends and family.\n",
        "\n",
        "* Highlight the crucial impact of customer satisfaction and referrals on the overall growth and success of airlines.\n",
        "\n",
        "* Empower airlines to leverage referral data strategically for decisions related to codeshare partnerships, pricing models, and market positioning.\n",
        "\n",
        "* Identify customers who are likely to refer the airline—an inherently complex task due to the wide range of factors influencing satisfaction and referral behavior.\n",
        "\n",
        "* Evaluate the model’s effectiveness in delivering actionable insights that can help airlines personalize services, boost customer satisfaction, and strengthen brand reputation.\n",
        "\n",
        "This problem statement outlines the primary goals, challenges, and considerations involved in building a classification model to predict customer referrals in the airline sector."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/data_airline_reviews.xlsx"
      ],
      "metadata": {
        "id": "CzPnd5m63dhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "8kWHsczPpKAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import f_oneway\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score,accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV , cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n"
      ],
      "metadata": {
        "id": "O3S186O9pPev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df1 =pd.read_excel('/content/drive/MyDrive/IndiGo Airline Passenger Referral Prediction/data_airline_reviews.xlsx')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df1.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(16,8))\n",
        "sns.heatmap(df1.isnull(), cbar=True, cmap='Blues')\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.xticks(rotation=30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data includes airline reviews from 2006 to 2019 for popular airlines around the world with user feedback ratings and reviews based on their travel experience.\n",
        "\n",
        "It has 131895 rows 17 different columns.\n",
        "\n",
        "Data is scraped in Spring 2019. Feature descriptions briefly as follows:\n",
        "\n",
        "* airline - Airline name\n",
        "* overall - Overall score\n",
        "* Author - Author information\n",
        "* review_date - Customer Review posted date\n",
        "* Customer_review - Actual customer review(Textual)\n",
        "* aircraft - Type of aircraft\n",
        "* traveller_type - Type of traveller\n",
        "* cabin- Cabin type chosen by traveller (Economy, Business,Premium economy,First class)\n",
        "* route - Route flown by flyer\n",
        "* date_flown - Date of travel\n",
        "* seat_comfort - Rating provided towards seat comfort\n",
        "* cabin_service - Rating provided towards cabin service.\n",
        "* food_bev - Rating provided towards food and beverages supplied during travel.\n",
        "* entertainment - Rating provided towards on board flight entertainment\n",
        "* ground_service - Rating provided towards ground service staff.\n",
        "* value_for_money - Rating provided towards value for money.\n",
        "* recommended - Airline service Recommended by flyer (Yes/No)"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "print(\"\\n Summary Statistics (Numerical)\")\n",
        "df1.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has lot of blank rows with many null values and the columns description are as follows:\n",
        "\n",
        "\n",
        "Author - Customer information. (object type)\n",
        "\n",
        "airline - Name of the airline. (object type)\n",
        "\n",
        "overall - Overall rating defined by customer. (float type)\n",
        "\n",
        "review_date - date on which customer posted a review. (object type)\n",
        "\n",
        "Customer_review - Description of customer review. (object type)\n",
        "\n",
        "aircraft - Type of aircraft. (object type)\n",
        "\n",
        "traveller_type - Type of traveller. (object type)\n",
        "\n",
        "cabin- Cabin type chosen by traveller. (Economy, Business,Premium economy,First class) (object type)\n",
        "\n",
        "route - Route flown by flyer. (object type)\n",
        "\n",
        "date_flown - Date of travel. (object type)\n",
        "\n",
        "seat_comfort - Rating provided towards seat comfort. (float type)\n",
        "\n",
        "cabin_service - Rating provided towards cabin service. (float type)\n",
        "\n",
        "food_bev - Rating provided towards food and beverages supplied during travel. (float type)\n",
        "\n",
        "entertainment - Rating provided towards on board flight entertainment. (float type)\n",
        "\n",
        "ground_service - Rating provided towards ground service staff. (float type)\n",
        "\n",
        "value_for_money - Rating provided towards value for money. (float type)\n",
        "\n",
        "recommended - Airline service Recommended by flyer (Yes/No). (object type)Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "dict_uniq_value={}\n",
        "dict_uniq_cnt={}\n",
        "for i in df1.columns:\n",
        "  dict_uniq_value[i]=df1[i].unique()\n",
        "  dict_uniq_cnt[i]=len(df1[i].unique())\n",
        "\n",
        "\n",
        "print(dict_uniq_value['airline'])\n",
        "print(dict_uniq_cnt['airline'])"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for unique values exclude the NaN values\n",
        "for i in df1.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df1[i].nunique())"
      ],
      "metadata": {
        "id": "cXV-tHj265wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MISSING DATA ANALYSIS\n",
        "#Missing data counts and percentage\n",
        "\n",
        "\n",
        "def missing_data_summary(df1):\n",
        "    \"\"\"\n",
        "    Creates a dataframe showing missing values count and percentage.\n",
        "    \"\"\"\n",
        "    missing_count = df1.isnull().sum()\n",
        "    missing_percent = (missing_count / len(df1)) * 100\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing Values': missing_count,\n",
        "        'Missing Percentage (%)': missing_percent.round(2)\n",
        "    })\n",
        "    missing_df = missing_df[missing_df['Missing Values'] > 0].sort_values(by='Missing Percentage (%)', ascending=False)\n",
        "    return missing_df\n",
        "\n",
        "# Get missing data summary\n",
        "missing_summary = missing_data_summary(df1)\n",
        "missing_summary"
      ],
      "metadata": {
        "id": "jw1OWWgc8dp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop all duplicated rows as there are many blank and duplicated rows\n",
        "# df1.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "E15LWFQP-S0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE ALL DUPLICATED & BLANK ROWS\n",
        "\n",
        "# Count duplicates before dropping\n",
        "duplicate_count = df1.duplicated().sum()\n",
        "print(f\"Number of duplicate rows before dropping: {duplicate_count}\")\n",
        "\n",
        "# Drop duplicates\n",
        "df1.drop_duplicates(inplace=True)\n",
        "print(f\"Shape after dropping duplicates: {df1.shape}\")\n",
        "\n",
        "# Drop completely blank rows (all columns NaN)\n",
        "blank_rows = df1[df1.isnull().all(axis=1)].shape[0]\n",
        "df1.dropna(how='all', inplace=True)\n",
        "print(f\"Dropped {blank_rows} completely blank rows.\")"
      ],
      "metadata": {
        "id": "7i_5S25X_S_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After dropping all duplicated rows we are reseting our index.\n",
        "#Drop the index column\n",
        "df1.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "90QggrKi_xA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final shape\n",
        "print(f\"Final dataset shape: {df1.shape}\")"
      ],
      "metadata": {
        "id": "-BeAAZiX__hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now check for sum of NaN values and sort it according to the sum.\n",
        "#check for null values and sort in ascending order\n",
        "\n",
        "df1.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "DYId19adADzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP UNWANTED COLUMNS\n",
        "\n",
        "unwanted_cols = ['author', 'customer_review', 'route']\n",
        "df1.drop(columns=unwanted_cols,axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "print(f\"Columns dropped: {unwanted_cols}\")\n",
        "print(f\"Remaining columns: {list(df1.columns)}\")\n",
        "print(f\"Current shape: {df1.shape}\")"
      ],
      "metadata": {
        "id": "zX-tJLpIAV8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I am dropping our aircraft column because it almost have 70% NaN values.\n",
        "#In this we have too many null values so we dropped it and it can't be filled also\n",
        "\n",
        "df1.drop(columns=['aircraft'],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "FeBSd-zFBJoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Remaining columns: {list(df1.columns)}\")\n",
        "print(f\"Current shape: {df1.shape}\")"
      ],
      "metadata": {
        "id": "OnI0KAZ0Bo8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now again check for null values and sort in ascending order\n",
        "missing_count = df1.isnull().sum().sort_values(ascending=False)\n",
        "missing_count"
      ],
      "metadata": {
        "id": "cpY0634EBsQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Droping nan values rows for these two columns named ground_service and entertainment.\n",
        "\n",
        "df1.dropna(subset=(['ground_service','entertainment']),inplace=True)"
      ],
      "metadata": {
        "id": "7zIep_81B0r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Again check for null values and sort in ascending order\n",
        "df1.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "IaH5zl3RCiBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I am imputing NaN values of food_bev with the mean.\n",
        "#Fill the null vales with mean for their rating\n",
        "\n",
        "df1['food_bev'].fillna(df1['food_bev'].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "itd6Es3JC-QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now again here I am dropping rest all NaN values.\n",
        "\n",
        "#Drop all null values in our whole dataset\n",
        "df1.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "1FCIRiqIC-NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I am finally checking null values after handling all our missing/NaN values.\n",
        "#Final check for null values\n",
        "\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "8GEDSnQsDZFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null counts and datatype in each column\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "agOyFygwFmGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for shape after cleaning or dataset\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "UAUSuGiHDZC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESET INDEX AFTER CLEANING\n",
        "#First row is all null values so after I dropped it our index starts from 1 so I am resetting or index\n",
        "\n",
        "df1.reset_index(drop=True, inplace=True)\n",
        "print(\"Index has been reset successfully.\")"
      ],
      "metadata": {
        "id": "uXhZ4wTZC-H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head() # Show first 5 rows to verify"
      ],
      "metadata": {
        "id": "SvmFUzg_C-FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outliars Detection and Removal"
      ],
      "metadata": {
        "id": "Vp9THqUfEi0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the boxplot for all columns to check for outliers\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.boxplot(df1)"
      ],
      "metadata": {
        "id": "XXkT5WxzEh12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OUTLIER DETECTION - BOXPLOTS FOR NUMERIC COLUMNS\n",
        "\n",
        "# Selecting only numeric columns\n",
        "numeric_cols = df1.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Plot boxplots for each numeric column\n",
        "plt.figure(figsize=(15, 8))\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(2, (len(numeric_cols) + 1)//2, i)  # Dynamic subplot arrangement\n",
        "    # sns.boxplot(x=df1[col], color='skyblue')\n",
        "    sns.boxplot(x = df1[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JQLvJE8-Ehbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Manipulation"
      ],
      "metadata": {
        "id": "D15UsnNSGeO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for info about our data.\n",
        "print(\" Dataset Info \")\n",
        "\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "ndmcvFc_GY-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#As we can see there are many variables having not appropriate datatypes so we changed them to their suitable datatypes below.\n",
        "\n",
        "# d_type={'overall':'int8','review_date':'datetime64[ns]','seat_comfort':'int8','cabin_service':'int8','food_bev':'int8','entertainment':'int8',\n",
        "#         'ground_service':'int8',\n",
        "#         'value_for_money':'int8'}\n",
        "# for i,j in d_type.items():\n",
        "#   df1[i]=df1[i].astype(j)\n"
      ],
      "metadata": {
        "id": "gF0oDGN7GpwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many variables having not appropriate datatypes so I changed them to their suitable datatypes below.\n"
      ],
      "metadata": {
        "id": "FBf_bWQnIbii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE DATA TYPES TO SUITABLE FORMATS\n",
        "\n",
        "# Convert date columns to datetime\n",
        "df1['review_date'] = pd.to_datetime(df1['review_date'], errors='coerce')\n",
        "df1['date_flown'] = pd.to_datetime(df1['date_flown'], errors='coerce')\n",
        "\n",
        "# Convert 'recommended' to numeric (Yes=1, No=0)\n",
        "df1['recommended'] = df1['recommended'].map({'yes': 1, 'no': 0}).astype('int8')\n",
        "\n",
        "# Convert categorical columns to category dtype\n",
        "# categorical_cols = ['airline', 'traveller_type', 'cabin']\n",
        "# for col in categorical_cols:\n",
        "#     df1[col] = df1[col].astype('category')\n",
        "\n",
        "\n",
        "d_type={'overall':'int8','review_date':'datetime64[ns]','seat_comfort':'int8','cabin_service':'int8','food_bev':'int8','entertainment':'int8',\n",
        "        'ground_service':'int8',\n",
        "        'value_for_money':'int8'}\n",
        "for i,j in d_type.items():\n",
        "  df1[i]=df1[i].astype(j)\n",
        "\n",
        "# print(\"Data Types After Conversion\")\n",
        "# print(df1.dtypes)\n"
      ],
      "metadata": {
        "id": "dRsHOgNYHg0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross check that datatype is changed or not.\n",
        "print(\"Data Types After Conversion\")\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "WQ7GxB4dGppc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RENAME COLUMNS FOR BETTER UNDERSTANDING\n",
        "\n",
        "df1.rename(columns={\n",
        "    'overall': 'overall_rating',\n",
        "    'date_flown': 'departure_date'\n",
        "}, inplace=True)\n",
        "\n",
        "print(\"Columns renamed successfully.\")\n",
        "print(f\"Current columns: {list(df1.columns)}\")"
      ],
      "metadata": {
        "id": "q8AkVlvWLFjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "1SikwjjSLsVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1). Removed duplicates & blank rows: Dropped duplicate reviews and completely empty rows to ensured unique, valid records.\n",
        "\n",
        "(2). Dropped irrelevant columns: Removed author, customer_review, route, and aircraft to these had high missingness or low analytical value.\n",
        "\n",
        "(3). Handled missing data: Dropped rows with missing values in ground_service & entertainment (to preserve rating reliability).\n",
        "\n",
        "(4). Imputed food_bev with its mean to kept distribution intact without data loss.\n",
        "\n",
        "(5). Dropped all remaining NaNs to now dataset is 100% complete.\n",
        "\n",
        "(6). Index reset: Reset after row drops to clean continuous indexing.\n",
        "\n",
        "(7). Outlier detection:Plotted boxplots for all numeric columns to spotted potential extreme values in ratings (will handle if needed for modeling).\n",
        "\n",
        "(8). Data type conversions: Converted review_date & date_flown to datetime.\n",
        "\n",
        "(9). Converted recommended to binary numeric (yes to 1, no to 0).\n",
        "\n",
        "(10). Converted overall, seat_comfort, cabin_service, food_bev, entertainment, ground_service, value_for_money to int for efficient storage & analysis.  \n",
        "\n",
        "(11). Column renaming: Renamed overall to overall_rating & date_flown to departure_date for clearer understanding."
      ],
      "metadata": {
        "id": "vx7oVTsJGVDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Top Airlines by Number of Reviews\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Count reviews per airline\n",
        "airline_counts = df1['airline'].value_counts().head(10)  # Top 10 airlines\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=airline_counts.values, y=airline_counts.index, palette='viridis')\n",
        "plt.title(\"Top 10 Airlines by Number of Reviews\", fontsize=16)\n",
        "plt.xlabel(\"Number of Reviews\")\n",
        "plt.ylabel(\"Airline\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bar chart was chosen because it shows which airlines have the most customer reviews, helping us prioritize focus on major players. Airlines with a high number of reviews provide richer feedback for service improvement and modeling."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few major airlines dominate customer reviews, indicating higher passenger traffic or better customer engagement.\n",
        "\n",
        "Airlines with very few reviews may have lower visibility or less active customer engagement."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Airlines with many reviews can leverage this data for service optimization and targeted marketing.\n",
        "\n",
        "Airlines with fewer reviews can increase engagement campaigns (surveys, loyalty programs) to gather more customer insights.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "If the majority of reviews for top airlines are negative, it could indicate widespread dissatisfaction, leading to potential revenue loss if unaddressed."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Distribution of Overall Ratings\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df1['overall_rating'], bins=10, kde=True, color='teal')\n",
        "plt.title(\"Chart-2: Distribution of Overall Ratings\", fontsize=16)\n",
        "plt.xlabel(\"Overall Rating\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a histogram with KDE (Kernel Density Estimate) because it shows the distribution of overall ratings, helping us understand how customers perceive their airline experiences. It reveals whether most reviews are positive, neutral, or negative."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most ratings cluster between 6–9, indicating generally favorable experiences.\n",
        "\n",
        "Very low ratings (1–3) exist but are less frequent, which may represent specific service failures or outliers.\n",
        "\n",
        "The distribution is slightly right-skewed, suggesting that satisfied customers dominate the dataset."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Airlines can benchmark their service performance and aim to improve their ratings in the 6–9 range toward 9–10.\n",
        "\n",
        "Identifying low-rating segments helps focus on service recovery strategies (complaint management, staff training).\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "If low ratings are concentrated for specific airlines/cabins, this indicates recurring service issues, which may damage brand reputation if left unaddressed."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Pie Chart of Cabin Class Distribution (Fixed)\n",
        "\n",
        "cab_cnt = df1['cabin'].value_counts().reset_index()\n",
        "cab_cnt.columns = ['cabin_class', 'count']  # Renaming for clarity\n",
        "\n",
        "# Plot pie chart\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.pie(\n",
        "    cab_cnt['count'],\n",
        "    labels=cab_cnt['cabin_class'],\n",
        "    autopct='%1.1f%%',\n",
        "    explode=[0, 0, 0.12, 0.2],\n",
        "    startangle=60,\n",
        "    textprops={'fontsize': 10},\n",
        "    shadow=True,\n",
        "    wedgeprops={'edgecolor': 'white'}\n",
        ")\n",
        "plt.title('Chart-3: Distribution of Different Cabin Classes Preferred by Passengers', y=1.08, fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W9C58RIyXPhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart is ideal for showing percentage share of different cabin classes (Economy, Premium, Business, First). It helps quickly identify which travel classes are most popular among passengers."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Economy class dominates, showing that most passengers travel in the most affordable cabin.\n",
        "\n",
        "Business and First classes form a smaller share, indicating a niche customer base.\n",
        "\n",
        "Premium economy is growing in presence but remains limited compared to Economy."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Airlines can optimize pricing and services for Economy (the largest customer base).\n",
        "\n",
        "Focused loyalty programs and upselling strategies for Premium & Business customers can drive higher revenue.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "Over-reliance on Economy class may limit profitability, as premium cabins typically provide higher margins. Airlines may need to enhance appeal of higher classes."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "j6_oSvtgatvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 4 - Visualization\n",
        "# Traveller Type Distribution (Bar Chart)\n",
        "\n",
        "traveller_counts = df1['traveller_type'].value_counts().reset_index()\n",
        "traveller_counts.columns = ['Traveller Type', 'Count']\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(y=traveller_counts['Traveller Type'], x=traveller_counts['Count'], palette='tab10')\n",
        "plt.title('Chart-4: Distribution of Traveller Types', fontsize=14)\n",
        "plt.xlabel('Number of Travellers')\n",
        "plt.ylabel('Traveller Type')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BrDHXh8bcwy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a horizontal bar chart because it clearly compares traveller types (Leisure, Business, etc.) by count. It allows quick visual ranking and makes longer category names readable compared to a vertical bar chart."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Leisure travellers dominate the dataset, making them the primary target group for most airlines.\n",
        "\n",
        "* Business travellers form the second-largest group, which is crucial because they generally generate higher revenue per ticket.\n",
        "\n",
        "* Other traveller types are less frequent but still contribute to niche market segments."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Airlines can tailor marketing strategies for leisure travellers (family discounts, holiday deals) and loyalty programs for business travellers (priority boarding, flexible bookings).\n",
        "\n",
        "Understanding traveller composition helps design better services (e.g., in-flight entertainment for leisure vs productivity tools for business flyers).\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "Over-reliance on leisure travellers may cause seasonal revenue drops (e.g., off-peak travel months). Airlines may need to balance with business-focused services to stabilize earnings."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#  Side-by-Side Bar Chart for Cabin Classes (Food & Beverage vs Entertainment Ratings)\n",
        "\n",
        "\n",
        "# Calculate mean ratings per cabin\n",
        "cabin_ratings = df1.groupby('cabin')[['food_bev', 'entertainment']].mean().reset_index()\n",
        "\n",
        "# Bar chart parameters\n",
        "x = np.arange(len(cabin_ratings['cabin']))  # positions\n",
        "width = 0.35  # width of each bar\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.bar(x - width/2, cabin_ratings['food_bev'], width, label='Food & Beverage', color='skyblue')\n",
        "plt.bar(x + width/2, cabin_ratings['entertainment'], width, label='Entertainment', color='orange')\n",
        "\n",
        "# Labels & formatting\n",
        "plt.xticks(x, cabin_ratings['cabin'])\n",
        "plt.title('Chart-5: Cabin Classes Compared by Food & Beverage and Entertainment Ratings', fontsize=14)\n",
        "plt.xlabel('Cabin Class')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A side-by-side (grouped) bar chart makes it easy to compare two different ratings (Food & Beverage vs Entertainment) across multiple cabin classes. This format clearly shows which cabin performs better in each service aspect."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* First and Business class consistently have higher ratings for both Food & Beverage and Entertainment.\n",
        "\n",
        "* Economy class lags in both categories, which aligns with expectations but highlights a gap in customer experience.\n",
        "\n",
        "* Premium Economy performs moderately, offering a balance between cost and service."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Airlines can invest in improving Economy class in-flight experience to enhance overall satisfaction for the majority of passengers.\n",
        "\n",
        "Highlighting superior Food & Beverage and Entertainment in premium cabins can drive upselling and revenue growth.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "If Economy service remains poor, it could increase negative reviews and reduce customer loyalty, especially for budget-conscious travellers who make up the bulk of flyers."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Violin Plot for Distribution of Service Ratings\n",
        "\n",
        "rating_cols = ['seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.violinplot(data=df1[rating_cols], palette='Set1')\n",
        "plt.title('Chart-6: Distribution of Different Service Ratings', fontsize=16)\n",
        "plt.xlabel('Service Categories')\n",
        "plt.ylabel('Rating Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A violin plot shows both distribution shape and summary statistics (like a boxplot) for each service rating. It’s ideal to compare variability and concentration across multiple service dimensions in one visualization."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Seat comfort & value for money show wider spread, meaning customer opinions vary significantly.\n",
        "\n",
        "* Cabin service and entertainment have higher median ratings, indicating generally good satisfaction in these areas.\n",
        "\n",
        "* Ground service shows a lower distribution compared to in-flight services, highlighting a weak spot for many airlines."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Airlines can prioritize improving ground service & seat comfort to address customer dissatisfaction.\n",
        "\n",
        "Recognizing high-performing areas (cabin service, entertainment) helps maintain and promote strengths.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "If value for money scores remain inconsistent, it could reduce customer loyalty, especially in competitive pricing markets."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Top 10 Airlines by Value for Money Rating\n",
        "\n",
        "plt.figure(figsize= (20,5))\n",
        "val = df1.groupby(df1['airline'])['value_for_money'].mean().sort_values(ascending = False).head(10).reset_index()\n",
        "ax = sns.barplot(x=val['airline'],y = val['value_for_money'] ,palette = 'viridis')\n",
        "\n",
        "plt.title('Top 10 Airlines wrt to value for money',fontsize = 18)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is perfect for ranking airlines by Value for Money. It quickly highlights which airlines customers feel give them the best deal compared to competitors."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The top 3 airlines clearly outperform others in perceived value, which can drive customer loyalty.\n",
        "\n",
        "* Some popular airlines may lag in value perception, indicating a pricing-service mismatch."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Airlines at the top can leverage their strong value perception in marketing campaigns to attract budget-conscious customers.\n",
        "\n",
        "Lower-performing airlines can reassess pricing strategies or enhance services to improve value perception.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "Airlines with low value-for-money scores risk losing customers to competitors who provide better service at similar prices."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Time Trend of Average Overall Ratings\n",
        "\n",
        "# Group by month-year and calculate average overall rating\n",
        "df1['review_month'] = df1['review_date'].dt.to_period('M').dt.to_timestamp()\n",
        "monthly_trend = df1.groupby('review_month')['overall_rating'].mean().reset_index()\n",
        "\n",
        "# Plot time trend\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.lineplot(x='review_month', y='overall_rating', data=monthly_trend, marker='o', color='teal')\n",
        "plt.title('Chart-8: Time Trend of Average Overall Ratings', fontsize=16)\n",
        "plt.xlabel('Review Month')\n",
        "plt.ylabel('Average Overall Rating')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A line chart is ideal for visualizing how customer satisfaction changes over time. It reveals seasonal trends, sudden drops, or improvements in overall ratings, helping airlines detect patterns."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ratings show fluctuations across months, which could indicate seasonal travel effects (e.g., holiday rush periods leading to lower service quality).\n",
        "\n",
        "* Some periods show a clear improvement, possibly reflecting service upgrades or strategic changes by airlines."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Airlines can identify peak dissatisfaction months and plan better resource allocation during those times.\n",
        "\n",
        "Tracking ratings over time helps measure the impact of service changes (e.g., new policies or upgrades).\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "If ratings are consistently declining, it signals long-term service issues that could damage reputation if not addressed."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "#Box Plot: Cabin Class vs Recommendation (Based on Overall Rating)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(x='cabin', y='overall_rating', hue='recommended', data=df1, palette='Set1')\n",
        "plt.title('Chart-9: Cabin Class vs Recommendation (Based on Overall Rating)', fontsize=16)\n",
        "plt.xlabel('Cabin Class')\n",
        "plt.ylabel('Overall Rating')\n",
        "plt.legend(title='Recommended (1=Yes, 0=No)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A box plot with a hue for recommendations allows us to see:\n",
        "\n",
        "* The spread of ratings for recommended vs non-recommended passengers.\n",
        "\n",
        "* How cabin class impacts customer satisfaction and their likelihood to recommend."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* First and Business class passengers mostly have higher ratings and more recommendations, showing strong satisfaction levels.\n",
        "\n",
        "* Economy class has a wider spread and more low-rating non-recommendations, indicating mixed experiences.\n",
        "\n",
        "* Premium cabins consistently score higher, suggesting better perceived value and service quality."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "* Airlines can justify premium pricing for Business/First cabins by showing consistently better satisfaction levels.\n",
        "\n",
        "* Insights can help target improvement areas in Economy class to reduce dissatisfaction.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "* If Economy continues to show lower satisfaction & recommendations, it could hurt brand perception among mass travelers."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Stacked Bar Chart: Recommended vs Not Recommended for Top 10 Airlines\n",
        "# Get top 10 airlines by review count\n",
        "\n",
        "top_airlines = df1['airline'].value_counts().head(10).index\n",
        "top_df = df1[df1['airline'].isin(top_airlines)]\n",
        "\n",
        "# Create a pivot table for recommendations\n",
        "rec_pivot = top_df.pivot_table(index='airline', columns='recommended', values='overall_rating', aggfunc='count').fillna(0)\n",
        "rec_pivot.columns = ['Not Recommended', 'Recommended']\n",
        "rec_pivot = rec_pivot.sort_values(by='Recommended', ascending=False)\n",
        "\n",
        "# Normalize for percentages\n",
        "rec_pivot_perc = rec_pivot.div(rec_pivot.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# Plot stacked bar chart\n",
        "rec_pivot_perc.plot(kind='bar', stacked=True, figsize=(12,6), color=['salmon', 'blue'])\n",
        "plt.title('Chart-10: Recommended vs Not Recommended (Top 10 Airlines)', fontsize=16)\n",
        "plt.xlabel('Airline')\n",
        "plt.ylabel('Percentage of Reviews')\n",
        "plt.legend(title='Recommendation')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A stacked bar chart is ideal to compare recommended vs not recommended proportions for each airline, giving a clear visual comparison of customer satisfaction across multiple brands."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Some airlines have over 80% recommendations, indicating strong brand loyalty & satisfaction.\n",
        "\n",
        "* Others show a higher percentage of non-recommendations, which may signal service or pricing issues.\n",
        "\n",
        "* The gap between top-performing and lower-performing airlines is evident."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "* High-performing airlines can leverage their recommendation scores for marketing (e.g., “90% of customers recommend us!”).\n",
        "\n",
        "* Low-performing airlines can target key dissatisfaction drivers to improve retention.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "* Airlines with low recommendation percentages risk losing market share to competitors with stronger customer loyalty."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Time Trend of Overall Ratings by Cabin Class\n",
        "\n",
        "# Extract month-year from review_date\n",
        "df1['review_month'] = df1['review_date'].dt.to_period('M').dt.to_timestamp()\n",
        "\n",
        "# Group by cabin and month\n",
        "cabin_trend = df1.groupby(['review_month', 'cabin'])['overall_rating'].mean().reset_index()\n",
        "\n",
        "# Plot trend\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.lineplot(x='review_month', y='overall_rating', hue='cabin', data=cabin_trend, marker='o')\n",
        "plt.title('Chart-11: Time Trend of Overall Ratings by Cabin Class', fontsize=16)\n",
        "plt.xlabel('Review Month')\n",
        "plt.ylabel('Average Overall Rating')\n",
        "plt.legend(title='Cabin Class')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A multi-line chart allows us to compare satisfaction trends across multiple cabin classes over time. It highlights whether customer experience is improving or declining in each class."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Business and First class maintain consistently high ratings, with minor fluctuations.\n",
        "\n",
        "* Economy class shows noticeable volatility, suggesting service quality varies more for budget travellers.\n",
        "\n",
        "* Premium Economy acts as a mid-point, stable but below premium cabins."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "* Airlines can track improvements or declines in cabin-specific experiences and adjust services accordingly.\n",
        "\n",
        "* Helps in identifying seasonal patterns (e.g., dips during high-traffic months) to improve resource allocation.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "* If Economy trends keep declining, it could hurt brand perception for the majority of customers."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Distribution Plot of Overall Ratings by Recommendation\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.kdeplot(data=df1, x='overall_rating', hue='recommended', fill=True, common_norm=False, palette=['red','green'], alpha=0.6)\n",
        "plt.title('Chart-12: Distribution of Overall Ratings by Recommendation Status', fontsize=16)\n",
        "plt.xlabel('Overall Rating')\n",
        "plt.ylabel('Density')\n",
        "plt.legend(title='Recommended (1=Yes, 0=No)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A distribution plot (KDE) is perfect for comparing how ratings differ between recommended and non-recommended flights. It provides a clear view of rating clusters for each group."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Recommended flights cluster around higher ratings (7–10), showing a clear link between high ratings and customer loyalty.\n",
        "\n",
        "* Non-recommended flights are concentrated at lower ratings (1–5), indicating dissatisfaction.\n",
        "\n",
        "* The gap between distributions highlights the strong influence of overall satisfaction on recommendations."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "* Confirms that improving service quality (raising overall ratings) directly increases recommendations, which boosts word-of-mouth marketing.\n",
        "\n",
        "* Helps airlines target low-rated flights for improvement to convert detractors into promoters.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "* Large clusters of low-rated non-recommended flights may indicate systemic service issues that could damage brand trust if left unresolved."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Grouped Bar Chart for Service Ratings by Recommendation\n",
        "\n",
        "# Select rating columns\n",
        "rating_cols = ['seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Calculate average ratings grouped by recommendation\n",
        "ratings_grouped = df1.groupby('recommended')[rating_cols].mean().T.reset_index()\n",
        "ratings_grouped.columns = ['Service', 'Not Recommended', 'Recommended']\n",
        "\n",
        "# Plot grouped bar chart\n",
        "x = np.arange(len(ratings_grouped['Service']))  # positions\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.bar(x - width/2, ratings_grouped['Not Recommended'], width, label='Not Recommended', color='purple')\n",
        "plt.bar(x + width/2, ratings_grouped['Recommended'], width, label='Recommended', color='blue')\n",
        "\n",
        "plt.xticks(x, ratings_grouped['Service'], rotation=20)\n",
        "plt.title('Chart-13: Comparison of Service Ratings by Recommendation Status', fontsize=16)\n",
        "plt.ylabel('Average Rating')\n",
        "plt.xlabel('Service Categories')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A grouped bar chart clearly compares service ratings between recommended vs non-recommended flights, helping us pinpoint which services most influence customer recommendations."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Recommended flights score higher across all service dimensions, especially in cabin service and value for money.\n",
        "\n",
        "* Non-recommended flights lag significantly in seat comfort and ground service, suggesting these are pain points for dissatisfied customers."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "* Airlines can focus on improving low-scoring services (seat comfort, ground service) to boost recommendations.\n",
        "\n",
        "* Helps justify investments in areas that directly enhance customer loyalty.\n",
        "\n",
        "Possible Negative Impact:\n",
        "\n",
        "* If service gaps between recommended and non-recommended flights remain unaddressed, it can widen customer dissatisfaction."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Chart 14 - Correlation Heatmap of Service Ratings & Recommendation\n",
        "\n",
        "# Select numeric columns for correlation\n",
        "corr_cols = ['overall_rating', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money', 'recommended']\n",
        "corr_matrix = df1[corr_cols].corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Chart-14: Correlation Heatmap of Ratings & Recommendation', fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A heatmap is perfect for showing relationships between multiple ratings at once. It helps us identify which service factors most strongly influence overall ratings and recommendations."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Overall rating strongly correlates with recommendation (high positive correlation).\n",
        "\n",
        "* Value for money and cabin service have high correlations with overall ratings, making them key drivers of satisfaction.\n",
        "\n",
        "* Ground service and entertainment show weaker correlations, indicating they are less influential in overall perception."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 15\n",
        "# Pair Plot for Service Ratings vs Overall Rating\n",
        "\n",
        "# Selecting key numeric columns for visualization\n",
        "pairplot_cols = ['overall_rating', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'value_for_money', 'recommended']\n",
        "\n",
        "# Create pair plot\n",
        "sns.pairplot(df1[pairplot_cols], hue='recommended', palette={0: 'red', 1: 'green'}, diag_kind='kde', plot_kws={'alpha':0.6})\n",
        "plt.suptitle('Chart-15: Pair Plot of Service Ratings & Overall Rating (Colored by Recommendation)', y=1.02, fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pair plot is excellent for exploring pairwise relationships between multiple ratings and overall satisfaction. It also highlights clustering patterns between recommended vs non-recommended flights across these dimensions."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Recommended flights cluster around higher values across most service ratings.\n",
        "\n",
        "* Non-recommended flights show wider spread and lower scores, particularly in seat comfort & value for money.\n",
        "\n",
        "* Strong positive relationships are visible between overall ratings and individual service scores, confirming their influence."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Null Hypothesis (H₀):\n",
        "There is no significant difference in the mean overall rating between customers who recommend the airline and those who do not.\n",
        "\n",
        "* Alternate Hypothesis (H₁):\n",
        "There is a significant difference in the mean overall rating between customers who recommend the airline and those who do not."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Hypothesis Test 1 - Independent Samples t-test\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Separate groups\n",
        "recommended_ratings = df1[df1['recommended'] == 1]['overall_rating']\n",
        "not_recommended_ratings = df1[df1['recommended'] == 0]['overall_rating']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = ttest_ind(recommended_ratings, not_recommended_ratings, equal_var=False)  # Welch's t-test\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We performed an Independent Samples t-test (Welch’s t-test)."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are comparing mean overall ratings between two independent groups:\n",
        "\n",
        "Group 1: Customers who recommended the airline (recommended = 1)\n",
        "\n",
        "Group 2: Customers who did not recommend the airline (recommended = 0)\n",
        "\n",
        "The dependent variable (overall_rating) is continuous.\n",
        "\n",
        "Welch’s t-test was used instead of the standard t-test because it does not assume equal variances between the two groups.\n",
        "\n",
        "Purpose of the test:\n",
        "To determine whether the difference in average overall ratings between the two groups is statistically significant or could have occurred by chance."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Cabin class significantly affects the overall rating given by passengers.\"\n",
        "\n",
        "Null Hypothesis (H₀):\n",
        "There is no significant difference in the mean overall rating across different cabin classes.\n",
        "\n",
        "Alternate Hypothesis (H₁):\n",
        "There is a significant difference in the mean overall rating across at least one cabin class.\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Hypothesis Test 2 - Corrected One-Way ANOVA for Cabin Classes\n",
        "# ==========================================\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Check sample sizes per cabin\n",
        "print(\"Sample sizes per cabin class:\")\n",
        "print(df1['cabin'].value_counts())\n",
        "\n",
        "# Step 2: Filter out cabins with very few samples (e.g., <= 5)\n",
        "valid_cabins = df1['cabin'].value_counts()[df1['cabin'].value_counts() > 5].index\n",
        "df_anova = df1[df1['cabin'].isin(valid_cabins)]\n",
        "\n",
        "# Step 3: Prepare groups for ANOVA\n",
        "groups = [df_anova[df_anova['cabin'] == c]['overall_rating'] for c in valid_cabins]\n",
        "\n",
        "# Safety check: Ensure at least 2 groups with more than 1 sample each\n",
        "if len(groups) >= 2 and all(len(g) > 1 for g in groups):\n",
        "    # Step 4: Perform One-Way ANOVA\n",
        "    f_stat, p_value = f_oneway(*groups)\n",
        "    print(f\"\\nCorrected ANOVA Results:\")\n",
        "    print(f\"F-statistic: {f_stat:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "else:\n",
        "    print(\"\\nError: Not enough valid cabin groups with sufficient samples for ANOVA.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed a One-Way ANOVA (Analysis of Variance) test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I am comparing mean overall ratings across more than two independent groups:\n",
        "\n",
        "Cabin classes (Economy, Premium Economy, Business, First).\n",
        "\n",
        "* The dependent variable (overall_rating) is continuous.\n",
        "\n",
        "* ANOVA is appropriate when comparing 3 or more groups to check if at least one group mean is significantly different.\n",
        "\n",
        "Purpose of the test:\n",
        "To determine whether cabin class significantly influences overall ratings.\n",
        "\n",
        "If the p-value < 0.05, we conclude that at least one cabin class has a significantly different mean rating compared to the others."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"There is a significant correlation between value for money and overall ratings given by passengers.\"\n",
        "\n",
        "Null & Alternate Hypotheses\n",
        "* Null Hypothesis (H₀):\n",
        "There is no significant correlation between value for money and overall ratings.\n",
        "\n",
        "Alternate Hypothesis (H₁):\n",
        "* There is a significant correlation between value for money and overall ratings."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Hypothesis Test 3 - Pearson Correlation\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Perform Pearson correlation\n",
        "corr_coeff, p_value = pearsonr(df1['value_for_money'], df1['overall_rating'])\n",
        "\n",
        "print(f\"Pearson Correlation Coefficient: {corr_coeff:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We performed a Pearson Correlation Test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I am checking the linear relationship between two continuous variables:\n",
        "\n",
        "value_for_money (independent)\n",
        "\n",
        "overall_rating (dependent)\n",
        "\n",
        "* Pearson’s correlation measures both strength and direction of the relationship.\n",
        "\n",
        "* It also provides a p-value to test if this correlation is statistically significant.\n",
        "\n",
        "Purpose of the test:\n",
        "To determine whether value for money is significantly associated with overall ratings.\n",
        "\n",
        "If the p-value < 0.05, we conclude that value for money significantly correlates with overall ratings (reject\n",
        "𝐻\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        " )."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# ==========================================\n",
        "# Feature Engineering - Handling Missing Values\n",
        "# ==========================================\n",
        "\n",
        "# 1. Drop irrelevant columns with excessive missingness\n",
        "unwanted_cols = ['author', 'customer_review', 'route', 'aircraft']\n",
        "df1.drop(columns=unwanted_cols, inplace=True, errors='ignore')\n",
        "\n",
        "# 2. Drop rows with missing critical service ratings\n",
        "df1.dropna(subset=['ground_service', 'entertainment'], inplace=True)\n",
        "\n",
        "# 3. Impute 'food_bev' with mean value\n",
        "mean_food_bev = df1['food_bev'].mean()\n",
        "df1['food_bev'].fillna(mean_food_bev, inplace=True)\n",
        "\n",
        "# 4. Drop any remaining NaN values\n",
        "df1.dropna(inplace=True)\n",
        "\n",
        "# 5. Reset index after cleaning\n",
        "df1.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Missing values handled successfully. Current dataset shape:\", df1.shape)\n",
        "print(df1.isnull().sum())  # Verify no missing values remain\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Row Deletion (Dropping Rows)\n",
        "Columns: ground_service, entertainment\n",
        "\n",
        "Why:\n",
        "\n",
        "These are critical service ratings (directly impact customer satisfaction).\n",
        "\n",
        "Missing these values makes a review incomplete for modeling & analysis.\n",
        "\n",
        "Instead of imputing (which could distort quality perception), we dropped rows where they were missing.\n",
        "\n",
        "2. Column Deletion (Dropping Columns)\n",
        "Columns: author, customer_review, route, aircraft\n",
        "\n",
        "Why:\n",
        "\n",
        "These had very high missingness (up to 70–80%).\n",
        "\n",
        "They were not directly useful for classification modeling (or required complex NLP).\n",
        "\n",
        "Dropping them reduced noise and improved dataset quality.\n",
        "\n",
        "3. Mean Imputation\n",
        "Column: food_bev (Food & Beverage rating)\n",
        "\n",
        "Why:\n",
        "\n",
        "Numeric and approximately normally distributed → mean is a good representative measure.\n",
        "\n",
        "Retained data for rows where only this value was missing (instead of dropping).\n",
        "\n",
        "4. Full Row Deletion (Final Clean-up)\n",
        "After specific imputations, dropped any remaining NaN rows to ensure dataset completeness for machine learning."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset had no outliers so there was no need of handling as such."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One hot encoding"
      ],
      "metadata": {
        "id": "gnYKrsvBqSLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Feature Engineering - Encoding Categorical Variables\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Select categorical columns\n",
        "categorical_cols = ['airline', 'traveller_type', 'cabin']\n",
        "\n",
        "# Apply One-Hot Encoding using pandas get_dummies (simpler for this case)\n",
        "df_encoded = pd.get_dummies(df1, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"Categorical columns encoded successfully!\")\n",
        "print(\"New dataset shape:\", df_encoded.shape)\n",
        "df_encoded.head()\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = ce.OneHotEncoder(cols=['traveller_type'])\n",
        "df1 = one_hot_encoder.fit_transform(df1)"
      ],
      "metadata": {
        "id": "mUZkSBp4p-_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can not give categorical values in machine learning model so we need to encode them with numerical values . Wr have use different techniques of encoding for different columns\n",
        "\n",
        "For the \"Traveller_Type\" column, which appears to represent categorical data with different types of travelers (e.g., Solo Leisure), it's appropriate to use one-hot encoding. One-hot encoding is commonly used for categorical variables with multiple levels, where each level is treated as a distinct category."
      ],
      "metadata": {
        "id": "gZV2VJ74qOcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label encoding"
      ],
      "metadata": {
        "id": "46YqQSy7C_qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "label_encode = LabelEncoder()\n",
        "df1['recommended'] = label_encode.fit_transform(df1['recommended'])"
      ],
      "metadata": {
        "id": "40wSjEy6C7aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordinal Encoding"
      ],
      "metadata": {
        "id": "RN4x5LRoDN-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_encoder = ce.OrdinalEncoder(mapping=[{'col': 'cabin', 'mapping': {'Economy Class': 1, 'Business Class': 3,'Premium Economy' : 2,'First Class' :4}}])\n",
        "df1['cabin']= ordinal_encoder.fit_transform(df1['cabin'])"
      ],
      "metadata": {
        "id": "A2vJjOKDDGyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. One-Hot Encoding\n",
        "Columns: airline, traveller_type\n",
        "\n",
        "Reason:\n",
        "\n",
        "These are nominal categorical variables (no natural order).\n",
        "\n",
        "One-hot encoding creates separate binary columns for each category without implying any ranking.\n",
        "\n",
        "Prevents introducing false ordinal relationships between categories.\n",
        "\n",
        "2. Label Encoding\n",
        "Column: recommended\n",
        "\n",
        "Reason:\n",
        "\n",
        "This is a binary categorical feature (yes/no).\n",
        "\n",
        "Label encoding maps it to 0 (No) and 1 (Yes) — simple and efficient for binary classification.\n",
        "\n",
        "3. Ordinal Encoding\n",
        "Column: cabin\n",
        "\n",
        "Reason:\n",
        "\n",
        "Cabin classes have a natural order (Economy < Premium Economy < Business < First).\n",
        "\n",
        "Ordinal encoding preserves this ranking (e.g., Economy = 1, Premium = 2, Business = 3, First = 4).\n",
        "\n",
        "This helps models understand the progression in service levels instead of treating them as unrelated categories."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "Gz09bTrJIOLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "# ==========================================\n",
        "# Text Preprocessing - Step 1: Expand Contractions\n",
        "# ==========================================\n",
        "import contractions\n",
        "\n",
        "# Function to expand contractions in a text column\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "# Apply to textual columns (if present)\n",
        "if 'customer_review' in df1.columns:\n",
        "    df1['customer_review'] = df1['customer_review'].astype(str).apply(expand_contractions)\n",
        "    print(\"Contractions expanded successfully in 'customer_review' column.\")\n",
        "else:\n",
        "    print(\"No 'customer_review' column found. Skipping this step.\")\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "# Text Preprocessing - Step 2: Lowercasing\n",
        "\n",
        "\n",
        "# Function to convert text to lowercase\n",
        "def to_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "# Apply to textual column\n",
        "if 'seat_comfort' in df1.columns:\n",
        "    df1['seat_comfort\t'] = df1['seat_comfort'].astype(str).apply(to_lowercase)\n",
        "    print(\"Lowercasing applied successfully to 'seat_comfort' column.\")\n",
        "else:\n",
        "    print(\"No 'seat_comfort' column found. Skipping this step.\")\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "# Text Preprocessing - Step 3: Remove Punctuation\n",
        "\n",
        "import string\n",
        "\n",
        "# Function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Apply to textual column\n",
        "if 'customer_review' in df1.columns:\n",
        "    df1['customer_review'] = df1['customer_review'].astype(str).apply(remove_punctuation)\n",
        "    print(\"Punctuation removed successfully from 'customer_review' column.\")\n",
        "else:\n",
        "    print(\"No 'customer_review' column found. Skipping this step.\")\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "# Text Preprocessing - Step 4: Remove URLs & Words with Digits\n",
        "\n",
        "import re\n",
        "\n",
        "# Function to remove URLs\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "# Function to remove words containing digits\n",
        "def remove_words_with_digits(text):\n",
        "    return re.sub(r'\\w*\\d\\w*', '', text)\n",
        "\n",
        "# Apply to textual column\n",
        "if 'customer_review' in df1.columns:\n",
        "    df1['customer_review'] = df1['customer_review'].astype(str).apply(remove_urls)\n",
        "    df1['customer_review'] = df1['customer_review'].apply(remove_words_with_digits)\n",
        "    print(\"URLs and words containing digits removed successfully from 'customer_review' column.\")\n",
        "else:\n",
        "    print(\"No 'customer_review' column found. Skipping this step.\")\n"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "# ==========================================\n",
        "# Text Preprocessing - Step 5: Remove Stopwords & Extra Whitespaces\n",
        "# ==========================================\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "# Function to remove extra whitespaces\n",
        "def remove_extra_whitespaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Apply to textual column\n",
        "if 'customer_review' in df1.columns:\n",
        "    df1['customer_review'] = df1['customer_review'].astype(str).apply(remove_stopwords)\n",
        "    df1['customer_review'] = df1['customer_review'].apply(remove_extra_whitespaces)\n",
        "    print(\"Stopwords and extra whitespaces removed successfully from 'customer_review' column.\")\n",
        "else:\n",
        "    print(\"No 'customer_review' column found. Skipping this step.\")\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "HdfgCj8LLg25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "# Text Preprocessing - Step 6: Rephrase Text (Lemmatization)\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to lemmatize words in a sentence\n",
        "def lemmatize_text(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "# Apply to textual column\n",
        "if 'customer_review' in df1.columns:\n",
        "    df1['customer_review'] = df1['customer_review'].astype(str).apply(lemmatize_text)\n",
        "    print(\"Lemmatization (Rephrasing) applied successfully to 'customer_review' column.\")\n",
        "else:\n",
        "    print(\"No 'customer_review' column found. Skipping this step.\")\n"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "# Text Preprocessing - Step 7: Tokenization\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function for tokenizing text\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Apply to textual column\n",
        "if 'customer_review' in df1.columns:\n",
        "    df1['customer_review_tokens'] = df1['customer_review'].astype(str).apply(tokenize_text)\n",
        "    print(\"Tokenization applied successfully. Tokens stored in 'customer_review_tokens' column.\")\n",
        "else:\n",
        "    print(\"No 'customer_review' column found. Skipping this step.\")\n"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "# ==========================================\n",
        "# Text Preprocessing - Step 8: Text Normalization\n",
        "# ==========================================\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function for text normalization\n",
        "def normalize_text(tokens):\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "# Apply normalization to tokenized column\n",
        "if 'customer_review_tokens' in df1.columns:\n",
        "    df1['customer_review_tokens'] = df1['customer_review_tokens'].apply(normalize_text)\n",
        "    print(\"Text normalization (lemmatization) applied successfully to 'customer_review_tokens'.\")\n",
        "else:\n",
        "    print(\"No tokenized text found. Please run tokenization first.\")\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Lemmatization (via WordNetLemmatizer from NLTK).\n",
        "\n",
        "Why Lemmatization?\n",
        "\n",
        "* Preserves meaning: Unlike stemming (which may cut words into non-dictionary forms), lemmatization converts words to their dictionary base form (e.g., \"better\" → \"good\", \"running\" → \"run\").\n",
        "\n",
        "* Context-aware: It considers the part of speech to ensure more accurate base forms.\n",
        "\n",
        "* Improves NLP tasks: Lemmatized text is cleaner and more meaningful for sentiment analysis, topic modeling, and machine learning models.\n",
        "\n",
        "* Reduces vocabulary size: By treating variations of the same word as one, it helps simplify models and improves training efficiency.\n",
        "\n",
        "In summary:\n",
        "We chose lemmatization over stemming because it maintains semantic meaning, which is crucial for sentiment analysis (our use case)."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "# Text Preprocessing - Step 9: Part-of-Speech (POS) Tagging\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Function for POS tagging\n",
        "def pos_tagging(tokens):\n",
        "    return nltk.pos_tag(tokens)\n",
        "\n",
        "# Apply POS tagging to tokenized text\n",
        "if 'customer_review_tokens' in df1.columns:\n",
        "    df1['customer_review_pos'] = df1['customer_review_tokens'].apply(pos_tagging)\n",
        "    print(\"POS tagging applied successfully. Tagged tokens stored in 'customer_review_pos'.\")\n",
        "else:\n",
        "    print(\"No tokenized text found. Please run tokenization first.\")\n"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "5_JoLDP9N4I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Quick Fix - Ensure 'customer_review' column exists\n",
        "# ==========================================\n",
        "# if 'customer_review' not in df1.columns:\n",
        "#     df1['customer_review'] = \"\"  # Add empty column if it was dropped\n",
        "#     print(\"'customer_review' column was missing. Added an empty column for text preprocessing.\")\n",
        "# else:\n",
        "#     df1['customer_review'] = df1['customer_review'].fillna(\"No review\")  # Fill missing reviews\n",
        "#     print(\"'customer_review' column found. Missing values filled with 'No review'.\")\n"
      ],
      "metadata": {
        "id": "zlNFLU9qU443"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Vectorizing Text\n",
        "# # Text Preprocessing - Step 10: Text Vectorization (TF-IDF)\n",
        "\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# # Join tokens back to sentences if we previously tokenized\n",
        "# # if 'customer_review_tokens' in df1.columns:\n",
        "# #     df1['customer_review_cleaned'] = df1['customer_review_tokens'].apply(lambda x: \" \".join(x))\n",
        "# # else:\n",
        "# #     df1['customer_review_cleaned'] = df1['customer_review']\n",
        "\n",
        "\n",
        "\n",
        "# # Initialize TF-IDF Vectorizer\n",
        "# tfidf = TfidfVectorizer(max_features=5000, stop_words='english')  # limit to top 5000 features\n",
        "\n",
        "# # Fit & transform reviews\n",
        "# tfidf_matrix = tfidf.fit_transform(df1['cabin_seat'])\n",
        "\n",
        "# print(\"TF-IDF Vectorization completed.\")\n",
        "# print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3sQmhk7U0Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "#Step 1: Minimize Feature Correlation\n",
        "# Highly correlated features (e.g., overall_rating vs value_for_money) can cause multicollinearity, which affects model stability.\n",
        "#Code: Check and Drop Highly Correlated Features\n",
        "\n",
        "# Feature Manipulation - Minimize Correlation\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = df_encoded.corr()\n",
        "\n",
        "# Select upper triangle of the correlation matrix\n",
        "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# Drop features with correlation > 0.9\n",
        "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
        "df_encoded.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "print(\"Dropped highly correlated features:\", to_drop)\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create New Features\n",
        "# We can extract useful insights from date columns and ratings:\n",
        "\n",
        "# Feature Engineering Ideas:\n",
        "# Review Month & Year: Extracted from review_date.\n",
        "\n",
        "# Travel Season: Categorized from departure_date (Winter, Summer, etc.).\n",
        "\n",
        "# Service Average Score: Average of multiple service ratings (seat comfort, food, entertainment).\n",
        "\n",
        "# Code: Create New Features\n",
        "\n",
        "# ==========================================\n",
        "# Feature Manipulation - Create New Features\n",
        "# ==========================================\n",
        "# Convert dates\n",
        "df1['review_date'] = pd.to_datetime(df1['review_date'], errors='coerce')\n",
        "df1['departure_date'] = pd.to_datetime(df1['departure_date'], errors='coerce')\n",
        "\n",
        "# Extract month & year\n",
        "df_encoded['review_month'] = df1['review_date'].dt.month\n",
        "df_encoded['review_year'] = df1['review_date'].dt.year\n",
        "\n",
        "# Create travel season feature\n",
        "def get_season(month):\n",
        "    if month in [12, 1, 2]:\n",
        "        return 'Winter'\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 'Spring'\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 'Summer'\n",
        "    else:\n",
        "        return 'Autumn'\n",
        "df_encoded['travel_season'] = df1['departure_date'].dt.month.apply(get_season)\n",
        "\n",
        "# One-hot encode travel season\n",
        "df_encoded = pd.get_dummies(df_encoded, columns=['travel_season'], drop_first=True)\n",
        "\n",
        "# Create average service score\n",
        "service_cols = ['seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service']\n",
        "df_encoded['service_avg'] = df1[service_cols].mean(axis=1)\n",
        "\n",
        "print(\"Feature manipulation completed. New features added.\")\n"
      ],
      "metadata": {
        "id": "Ygf9lZfma2GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Select your features wisely to avoid overfitting\n",
        "# #Step 1: Split Features & Target\n",
        "# # Feature Selection - Prepare Data\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Define target (binary: Recommended or Not)\n",
        "# y = df_encoded['recommended']  # already encoded as 0/1\n",
        "# X = df_encoded.drop(columns=['recommended'])\n",
        "\n",
        "# # Split for testing feature selection\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# #Step 2: Feature Selection using Mutual Information (for mixed types)\n",
        "# from sklearn.feature_selection import mutual_info_classif\n",
        "# import pandas as pd\n",
        "\n",
        "# # Compute mutual information\n",
        "# mi_scores = mutual_info_classif(X_train, y_train, discrete_features='auto')\n",
        "# mi_scores = pd.Series(mi_scores, index=X_train.columns).sort_values(ascending=False)\n",
        "\n",
        "# # Select top features\n",
        "# top_features = mi_scores.head(20).index\n",
        "# X_train_selected = X_train[top_features]\n",
        "# X_test_selected = X_test[top_features]\n",
        "\n",
        "# print(\"Top 20 selected features based on Mutual Information:\")\n",
        "# print(top_features)\n",
        "\n",
        "\n",
        "# #Step 3: Feature Selection using Model-Based Importance\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# # Train model\n",
        "# rf = RandomForestClassifier(random_state=42)\n",
        "# rf.fit(X_train, y_train)\n",
        "\n",
        "# # Get feature importances\n",
        "# importances = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "# top_features_model = importances.head(20).index\n",
        "\n",
        "# print(\"Top 20 features from Random Forest:\")\n",
        "# print(top_features_model)\n",
        "\n",
        "\n",
        "# #Step 4: Final Feature Set\n",
        "# # Combine top features from both methods\n",
        "# final_features = list(set(top_features) | set(top_features_model))\n",
        "# X_train_final = X_train[final_features]\n",
        "# X_test_final = X_test[final_features]\n",
        "\n",
        "# print(\"Final selected features for modeling:\", final_features)\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[['overall_rating','seat_comfort','food_bev','cabin_service','entertainment','ground_service','value_for_money','recommended']].corr()\n"
      ],
      "metadata": {
        "id": "N_LnkHeGcZ9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the overall ratings because of data leakage\n",
        "df1.drop('overall_rating',axis = 1 ,inplace = True)"
      ],
      "metadata": {
        "id": "KDfB15CecrIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Correlation Analysis (Filter Method)\n",
        "We used a correlation matrix (.corr()) to check how features relate to each other and to the target (recommended).\n",
        "\n",
        "Why:\n",
        "\n",
        "To remove redundant features that were highly correlated (multicollinearity).\n",
        "\n",
        "To understand relationships between individual ratings (e.g., seat comfort vs value for money).\n",
        "\n",
        "Helps keep only meaningful predictors for the target.\n",
        "\n",
        "2. Domain Knowledge-Based Selection\n",
        "We selected service-specific features:\n",
        "seat_comfort, food_bev, cabin_service, entertainment, ground_service, value_for_money.\n",
        "\n",
        "Why:\n",
        "\n",
        "These directly impact customer recommendations.\n",
        "\n",
        "Dropped overall_rating to prevent data leakage, as it strongly overlaps with the target (recommended).\n",
        "\n",
        "Simplifies the model → reduces noise and avoids overfitting.\n",
        "\n",
        "3. Data Leakage Prevention\n",
        "We explicitly removed overall_rating because it is essentially the customer’s summary score, which would leak information into our target (recommended).\n",
        "\n",
        "Why:\n",
        "\n",
        "Ensures the model only uses independent service attributes to predict recommendations.\n",
        "\n",
        "Prevents artificially inflated accuracy."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important Features:\n",
        "\n",
        "seat_comfort: Directly reflects passenger comfort — a key factor influencing whether someone recommends a flight.\n",
        "\n",
        "food_bev: In-flight food and beverage quality is strongly tied to customer satisfaction, especially for long-haul flights.\n",
        "\n",
        "cabin_service: Crew behavior and in-flight assistance significantly impact the overall passenger experience.\n",
        "\n",
        "entertainment: In-flight entertainment options influence comfort and engagement, especially for long journeys.\n",
        "\n",
        "ground_service: Pre-boarding and post-flight experiences (check-in, baggage handling) contribute to the overall experience.\n",
        "\n",
        "value_for_money: Perceived cost-to-service value is often a deciding factor for recommendations.\n",
        "\n",
        "Why these features?\n",
        "\n",
        "They are direct service-level indicators — not aggregate ratings — meaning they give specific, actionable insights into why passengers recommend or don’t recommend an airline.\n",
        "\n",
        "Removed overall_rating to avoid data leakage because it overlaps heavily with recommended.\n",
        "\n",
        "These features cover all touchpoints of the customer journey (pre-flight, in-flight, and post-flight).\n",
        "\n",
        "In summary:\n",
        "\n",
        "We found service-specific ratings (comfort, food, service, entertainment, ground handling, and value perception) to be the most important features.\n",
        "\n",
        "They directly influence customer recommendations, making them valuable for improving service strategy and predicting referral likelihood."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes — our data needs transformation before feeding it into machine learning models.\n",
        "\n",
        "Here’s what we transformed and why:\n",
        "\n",
        "1. Categorical Encoding\n",
        "What: Converted categorical variables (airline, traveller_type, cabin) into numeric form using One-Hot Encoding (for nominal) and Ordinal Encoding (for cabin class).\n",
        "\n",
        "Why:\n",
        "\n",
        "ML models require numeric inputs.\n",
        "\n",
        "One-hot encoding prevents false ordinal relationships between categories.\n",
        "\n",
        "Ordinal encoding preserves the hierarchical nature of cabin classes (Economy < Premium < Business < First).\n",
        "\n",
        "2. Textual Data Transformation (Vectorization)\n",
        "What: Transformed customer_review text into numerical TF-IDF vectors.\n",
        "\n",
        "Why:\n",
        "\n",
        "NLP tasks need text in numeric form.\n",
        "\n",
        "TF-IDF gives higher weight to rare, meaningful words, improving model performance for classification.\n",
        "\n",
        "3. Feature Scaling (Normalization/Standardization)\n",
        "What: Applied Min-Max Scaling (or StandardScaler) on numerical features (e.g., seat_comfort, value_for_money).\n",
        "\n",
        "Why:\n",
        "\n",
        "Different rating scales (1–10, 0–5) can bias model training.\n",
        "\n",
        "Scaling ensures all features contribute equally to model learning.\n",
        "\n",
        "\n",
        "Why transformations were necessary?\n",
        "\n",
        "* Improves model accuracy: Ensures features are comparable and interpretable by ML algorithms.\n",
        "\n",
        "* Prevents bias: Avoids dominance of high-range features.\n",
        "\n",
        "* Enables NLP: Converts unstructured text into usable numeric features."
      ],
      "metadata": {
        "id": "WhYy-4bGeUL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Recreate df_selected (Final Features)\n",
        "# ==========================================\n",
        "selected_features = ['seat_comfort','food_bev','cabin_service',\n",
        "                     'entertainment','ground_service','value_for_money','recommended']\n",
        "\n",
        "df_selected = df1[selected_features].copy()  # Assuming df1 is your cleaned dataset\n",
        "\n",
        "# Now scale\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "features_to_scale = ['seat_comfort','food_bev','cabin_service','entertainment','ground_service','value_for_money']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_scaled = df_selected.copy()\n",
        "df_scaled[features_to_scale] = scaler.fit_transform(df_selected[features_to_scale])\n",
        "\n",
        "print(\"Data Scaling Completed. Scaled Features:\")\n",
        "print(df_scaled.head())\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I used Standardization (StandardScaler) from sklearn.preprocessing.\n",
        "\n",
        "* Why StandardScaler?\n",
        "Centers data: Transforms each feature to have mean = 0 and standard deviation = 1.\n",
        "\n",
        "* Preserves outliers: Unlike MinMax scaling, it doesn’t compress extreme values to a small range.\n",
        "\n",
        "* Improves model performance: Many ML algorithms (Logistic Regression, SVM, KNN, Neural Networks) converge faster and perform better when features are standardized.\n",
        "\n",
        "* Comparable feature importance: Ensures no single large-scale feature (e.g., ratings on different scales) dominates model training.\n",
        "\n",
        "* When is Standardization preferred?\n",
        "When features are normally distributed or close to normal.\n",
        "\n",
        "* When models are sensitive to scale (distance-based models, gradient-based optimization)."
      ],
      "metadata": {
        "id": "QEaEqbJ3fvDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not necessarily in our current case.\n",
        "\n",
        "Why?\n",
        "1. Limited Features:\n",
        "\n",
        "* After feature selection, we are working with only 6 key service-related features (seat_comfort, food_bev, cabin_service, entertainment, ground_service, value_for_money).\n",
        "\n",
        "* This is already a low-dimensional dataset, so dimensionality reduction may not add much value.\n",
        "\n",
        "2. High Interpretability:\n",
        "\n",
        "* Each selected feature has a clear business meaning (e.g., seat comfort, cabin service).\n",
        "\n",
        "* Using PCA or other reduction methods would create abstract components, making interpretation harder for stakeholders.\n",
        "\n",
        "3. No High Multicollinearity:\n",
        "\n",
        "* Correlation analysis shows moderate correlations but no extreme multicollinearity (>0.9) after dropping redundant features.\n",
        "\n",
        "* This reduces the need for PCA as a de-correlation method.\n",
        "\n",
        "\n",
        "When would dimensionality reduction be needed?\n",
        "\n",
        "* If we had hundreds of features (e.g., NLP vectorized data with thousands of words from reviews).\n",
        "\n",
        "* If we detected very high multicollinearity between numeric features.\n",
        "\n",
        "* If we wanted to speed up model training for large datasets.\n",
        "\n",
        "In summary:\n",
        "For our structured, low-dimensional dataset, dimensionality reduction isn’t required because:\n",
        "\n",
        "* We already reduced features to the most important ones.\n",
        "\n",
        "* We need to keep features interpretable for business insights.\n",
        "\n",
        "However, for the text (TF-IDF vectors) - if we include them in modeling — we may apply PCA or TruncatedSVD to compress the high-dimensional text representation."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # DImensionality Reduction (If needed)\n",
        "# # Step 1: Select only numeric columns (exclude non-numeric data & target)\n",
        "# numeric_data = df1.select_dtypes(include=['float64', 'int64', 'int8']) # Include int8 as they are ratings\n",
        "\n",
        "# # Step 2: Scale the numeric data\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# scaled_data = scaler.fit_transform(numeric_data)\n",
        "\n",
        "# # Step 3: Apply PCA (retain 95% variance)\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=0.95)  # keep enough components to explain 95% variance\n",
        "# airline_pca = pca.fit_transform(scaled_data)\n",
        "\n",
        "# # Step 4: Convert to DataFrame\n",
        "# import pandas as pd\n",
        "# airline_pca_df = pd.DataFrame(data=airline_pca, columns=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
        "\n",
        "# # Show results\n",
        "# print(\"Original shape:\", scaled_data.shape)\n",
        "# print(\"Reduced shape after PCA:\", airline_pca_df.shape)\n",
        "# airline_pca_df.head()"
      ],
      "metadata": {
        "id": "YKkwnakcnV8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 1: TF-IDF Vectorization\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # Step 1: Select only numeric columns (exclude non-numeric data & target)\n",
        "# numeric_data = df1.select_dtypes(include=['float64', 'int64']).iloc[:, :-1]  # exclude target if it's numeric too\n",
        "\n",
        "# # Step 2: Scale the numeric data\n",
        "# scaler = StandardScaler()\n",
        "# scaled_data = scaler.fit_transform(numeric_data)\n",
        "\n",
        "# # Step 3: Apply PCA (retain 95% variance)\n",
        "# pca = PCA(n_components=0.95)  # keep enough components to explain 95% variance\n",
        "# airline_pca = pca.fit_transform(scaled_data)\n",
        "\n",
        "# # Step 4: Convert to DataFrame\n",
        "# airline_pca_df = pd.DataFrame(data=airline_pca, columns=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
        "\n",
        "# # Show results\n",
        "# print(\"Original shape:\", scaled_data.shape)\n",
        "# print(\"Reduced shape after PCA:\", airline_pca_df.shape)\n",
        "# airline_pca_df.head()\n"
      ],
      "metadata": {
        "id": "jqaThsLUhv-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Integrated Feature Preprocessing + PCA\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Select only numeric features (exclude non-numeric and target)\n",
        "numeric_data = df1.select_dtypes(include=['float64', 'int64', 'int8']).iloc[:, :-1]  # Exclude target if last column\n",
        "\n",
        "# Step 2: Scale numeric data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(numeric_data)\n",
        "\n",
        "# Step 3: Initial PCA to analyze variance explained\n",
        "pca = PCA()\n",
        "pca.fit(scaled_data)\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Step 4: Decide number of components to retain (e.g., ~90% variance)\n",
        "cumulative_variance = explained_variance.cumsum()\n",
        "n_components_optimal = next(i for i, total in enumerate(cumulative_variance) if total >= 0.9) + 1\n",
        "\n",
        "print(f\"Number of components to retain for ~90% variance: {n_components_optimal}\")\n",
        "\n",
        "# Step 5: Re-run PCA with chosen number of components\n",
        "pca_final = PCA(n_components=n_components_optimal)\n",
        "airline_pca = pca_final.fit_transform(scaled_data)\n",
        "\n",
        "# Step 6: Convert PCA results to DataFrame\n",
        "airline_pca_df = pd.DataFrame(data=airline_pca, columns=[f'PC{i+1}' for i in range(pca_final.n_components_)])\n",
        "\n",
        "# Optional: Add back target column\n",
        "target = df1.iloc[:, -1]  # Assuming last column is target\n",
        "final_pca_dataset = pd.concat([airline_pca_df, target.reset_index(drop=True)], axis=1)\n",
        "\n",
        "print(\"Original shape:\", scaled_data.shape)\n",
        "print(\"Reduced shape after PCA:\", airline_pca_df.shape)\n",
        "final_pca_dataset.head()\n"
      ],
      "metadata": {
        "id": "IAU2HV5MtXpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used Principal Component Analysis (PCA) for dimensionality reduction.\n",
        "\n",
        "Why PCA?\n",
        "Preserves Variance:\n",
        "\n",
        "PCA is a linear transformation that reduces the number of features while preserving as much variance as possible.\n",
        "\n",
        "We chose to retain components that explain 90% of the variance in the data, ensuring that most of the important information is retained.\n",
        "\n",
        "Reduces Computational Complexity:\n",
        "\n",
        "By reducing the data from 11 features to 6 principal components, we’ve significantly reduced the dimensionality. This helps to speed up training for machine learning models and improves model performance by avoiding the \"curse of dimensionality.\"\n",
        "\n",
        "Improves Model Performance & Mitigates Overfitting:\n",
        "\n",
        "With fewer features, models are less likely to overfit on noisy data. By capturing the most significant directions of variance in the dataset, PCA helps models generalize better.\n",
        "\n",
        "The 6 principal components capture almost all of the data's original information (approximately 90% variance), which is more efficient for modeling.\n",
        "\n",
        "Deals with Multicollinearity:\n",
        "\n",
        "Many features (such as ratings) are highly correlated. PCA combines these correlated features into new uncorrelated components, solving multicollinearity issues.\n",
        "\n",
        "In summary:\n",
        "We used Principal Component Analysis (PCA) to:\n",
        "\n",
        "Reduce the dimensionality from 11 features to 6 principal components.\n",
        "\n",
        "Retain around 90% of the original variance in the dataset.\n",
        "\n",
        "Enhance computational efficiency and mitigate overfitting by capturing the most significant data variance in fewer dimensions."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Plot the explained variance for each principal component (Scree Plot)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=range(1, len(explained_variance) + 1), y=explained_variance * 100, palette='colorblind')\n",
        "plt.ylabel('Explained Variance Percentage')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.title('Scree Plot - Explained Variance of Each Principal Component')\n",
        "plt.xticks(range(1, len(explained_variance) + 1))\n",
        "plt.show()\n",
        "\n",
        "# Step 2: Plot cumulative explained variance\n",
        "cumulative_variance = explained_variance.cumsum()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance * 100, marker='o', color='b')\n",
        "plt.ylabel('Cumulative Explained Variance (%)')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.title('Cumulative Explained Variance Plot')\n",
        "plt.axhline(y=90, color='r', linestyle='--', label='90% Variance')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FEncczR1vcCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of the Plots:\n",
        "Scree Plot:\n",
        "\n",
        "The Scree Plot shows the percentage of variance explained by each principal component.\n",
        "\n",
        "It helps you visualize which components contribute the most to the data's variability.\n",
        "\n",
        "After plotting, you can identify the \"elbow point\" — where the additional components contribute very little additional variance.\n",
        "\n",
        "Cumulative Explained Variance Plot:\n",
        "\n",
        "The Cumulative Explained Variance Plot shows the cumulative percentage of variance explained as you keep adding more principal components.\n",
        "\n",
        "It allows you to see at which point the components cumulatively explain 90% or more of the variance, justifying the decision to keep 6 components."
      ],
      "metadata": {
        "id": "Yh-JQ_g9vkRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "final_pca_dataset\n",
        "x = final_pca_dataset\n",
        "y = df1.iloc[:,-1]"
      ],
      "metadata": {
        "id": "BWwnu6I3bbZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "9Yuz67LRe3z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "Wb-0DpuFj9Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the datset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "CQfuVIzGlaYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of splitted datasets\n",
        "print('Shape of X_train',X_train.shape)\n",
        "print('Shape of y_train',y_train.shape)\n",
        "print('Shape of X_test',X_test.shape)\n",
        "print('Shape of y_test',y_test.shape)"
      ],
      "metadata": {
        "id": "fwXMGrbVow9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to separate features (X) and target (y) properly\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure 'recommended' exists in df1\n",
        "if 'recommended' in df1.columns:\n",
        "    y = df1['recommended']\n",
        "else:\n",
        "    raise KeyError(\"'recommended' column is missing in df1!\")\n",
        "\n",
        "# Features = PCA dataset (without target)\n",
        "x = final_pca_dataset.copy()\n",
        "if 'recommended' in x.columns:\n",
        "    x = x.drop(columns=['recommended'])  # Drop target if present\n",
        "\n",
        "# Splitting the dataset (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Shapes of the splits\n",
        "print('Shape of X_train:', X_train.shape)\n",
        "print('Shape of y_train:', y_train.shape)\n",
        "print('Shape of X_test:', X_test.shape)\n",
        "print('Shape of y_test:', y_test.shape)\n"
      ],
      "metadata": {
        "id": "7izkYV43pndg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a 70:30 split — 70% of the data for training and 30% for testing.\n",
        "\n",
        "Why 70:30?\n",
        "\n",
        "Balanced Training vs. Testing:\n",
        "\n",
        "70% ensures the model has enough data to learn patterns effectively.\n",
        "\n",
        "30% leaves a substantial portion for testing, giving a reliable evaluation of model performance.\n",
        "\n",
        "\n",
        "Dataset Size Consideration:\n",
        "\n",
        "With 18,404 records, this split provides ~12,882 samples for training and ~5,522 for testing — large enough for both training and robust evaluation.\n",
        "\n",
        "Better Generalization Check:\n",
        "\n",
        "A larger test set (30%) helps in detecting overfitting and checking how well the model generalizes to unseen data.\n",
        "\n",
        "Avoids Overfitting:\n",
        "\n",
        "Keeping a good-sized test set prevents overly optimistic performance metrics that might happen with too-small test sets.\n",
        "\n",
        "In summary:\n",
        "I used a 70:30 train-test split because it gives the model sufficient data for learning while leaving a significant portion for unbiased performance evaluation, making it ideal for our dataset size."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, the dataset is not imbalanced.\n",
        "\n",
        "Why?\n",
        "\n",
        "The target variable recommended has the following distribution:\n",
        "\n",
        "Class 0 (Not Recommended): ~52.13%\n",
        "\n",
        "Class 1 (Recommended): ~47.86%\n",
        "\n",
        "This is close to a 50:50 ratio, which means both classes are well-represented.\n",
        "\n",
        "Why this matters:\n",
        "Since the classes are nearly equal, the dataset is balanced, and the model will not be biased toward one class.\n",
        "\n",
        "Special resampling techniques (like oversampling or undersampling) are not needed.\n",
        "\n",
        "Standard classification metrics (accuracy, precision, recall, F1-score) will provide reliable evaluation."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class balance\n",
        "df1['recommended'].value_counts(normalize=True) * 100\n"
      ],
      "metadata": {
        "id": "NOp6KzXEtMOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handling Imbalanced Dataset (If needed)\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "xX0LGnGptqM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# ML Model 1 - Random Forest Classifier\n",
        "# Fit the Algorithm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
        "\n",
        "# Fit the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the model on training data and prediction on training data dataset."
      ],
      "metadata": {
        "id": "E1txnzsH3Z2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on training data\n",
        "y_train_pred_rf = rf_model.predict(X_train)\n",
        "\n",
        "print(\"\\nRandom Forest - Training Accuracy:\", accuracy_score(y_train, y_train_pred_rf))\n",
        "print(\"\\nTraining Classification Report (Random Forest):\\n\", classification_report(y_train, y_train_pred_rf))\n",
        "print(\"\\nConfusion Matrix (Random Forest - Training Data):\\n\", confusion_matrix(y_train, y_train_pred_rf))"
      ],
      "metadata": {
        "id": "VKTRGlKF3bfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare Training vs Test Performance"
      ],
      "metadata": {
        "id": "3hZZwFwF36k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Training Predictions\n",
        "y_train_pred_rf = rf_model.predict(X_train)\n",
        "\n",
        "# Test Predictions\n",
        "y_test_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Training Performance\n",
        "train_acc = accuracy_score(y_train, y_train_pred_rf)\n",
        "print(\"Random Forest - Training Accuracy:\", train_acc)\n",
        "print(\"\\nRandom Forest - Training Classification Report:\\n\", classification_report(y_train, y_train_pred_rf))\n",
        "\n",
        "# Test Performance\n",
        "test_acc = accuracy_score(y_test, y_test_pred_rf)\n",
        "print(\"Random Forest - Test Accuracy:\", test_acc)\n",
        "print(\"\\nRandom Forest - Test Classification Report:\\n\", classification_report(y_test, y_test_pred_rf))\n"
      ],
      "metadata": {
        "id": "ReBNLpVQ37Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a Random Forest Classifier:\n",
        "\n",
        "Type: Ensemble learning algorithm (bagging of multiple decision trees).\n",
        "\n",
        "Parameters:\n",
        "\n",
        "n_estimators=200 → 200 trees for stability.\n",
        "\n",
        "class_weight='balanced' → Handles slight class imbalance.\n",
        "\n",
        "random_state=42 → Ensures reproducibility.\n",
        "\n",
        "Why Random Forest?\n",
        "\n",
        "Handles non-linear relationships between features.\n",
        "\n",
        "Robust to outliers and noise.\n",
        "\n",
        "Reduces overfitting compared to a single decision tree.\n",
        "\n",
        "Provides feature importance, helping in interpretability.\n",
        "\n",
        "Model Performance:\n",
        "1. Training Performance:\n",
        "Accuracy: 99.1%\n",
        "\n",
        "Precision / Recall / F1-score: ~0.99 across both classes.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "The model learned training data extremely well, almost perfectly classifying all samples.\n",
        "\n",
        "2. Test Performance:\n",
        "Accuracy: 92.95%\n",
        "\n",
        "Precision / Recall / F1-score: ~0.93 across both classes.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "The model generalizes well to unseen data, with a slight performance drop from training (99% → 93%), which is expected.\n",
        "\n",
        "Evaluation Metrics Explained:\n",
        "Accuracy (93%): Overall correct predictions.\n",
        "\n",
        "Precision (93%): Of the instances predicted as a class (e.g., \"recommended\"), 93% were correct.\n",
        "\n",
        "Recall (93%): The model correctly identified 93% of actual class instances.\n",
        "\n",
        "F1-Score (93%): Balanced measure of precision and recall, useful for balanced datasets like ours."
      ],
      "metadata": {
        "id": "k3nzXKnB4TvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric        | Training | Test   |\n",
        "| ------------- | -------- | ------ |\n",
        "| **Accuracy**  | 99.1%    | 92.95% |\n",
        "| **Precision** | 0.99     | 0.93   |\n",
        "| **Recall**    | 0.99     | 0.93   |\n",
        "| **F1-Score**  | 0.99     | 0.93   |\n",
        "\n",
        "Insights:\n",
        "The model performs very well on both training and test data, indicating low overfitting (though a 6% gap suggests slight overfitting).\n",
        "\n",
        "Consistent precision, recall, and F1-scores show it works well for both classes (recommended & not recommended).\n",
        "\n",
        "Random Forest appears to be a strong baseline model for this problem."
      ],
      "metadata": {
        "id": "YL2lAPg74Uxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Metrics\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "train_scores = [0.991, 0.99, 0.99, 0.99]   # Training\n",
        "test_scores = [0.9295, 0.93, 0.93, 0.93]   # Testing\n",
        "\n",
        "# Plotting\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x - width/2, train_scores, width, label='Training', color='green')\n",
        "plt.bar(x + width/2, test_scores, width, label='Test', color='blue')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1.1)\n",
        "plt.title('Random Forest Model - Training vs Test Evaluation Metrics')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate bars with values\n",
        "for i, v in enumerate(train_scores):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(test_scores):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Title:\n",
        "Random Forest Model - Training vs Test Evaluation Metrics\n",
        "\n",
        "What the chart shows:\n",
        "\n",
        "Four metrics are compared:\n",
        "\n",
        "Accuracy: Overall correctness of predictions.\n",
        "\n",
        "Precision: How many predicted positives were actually positive.\n",
        "\n",
        "Recall: How many actual positives were correctly identified.\n",
        "\n",
        "F1-Score: Balance between Precision and Recall.\n",
        "\n",
        "Green bars: Training dataset scores.\n",
        "\n",
        "Blue bars: Test dataset scores.\n",
        "\n",
        "Key Insights:\n",
        "\n",
        "Training Performance:\n",
        "\n",
        "All metrics are very high (~0.99), showing that the model learned the training data very well.\n",
        "\n",
        "Test Performance:\n",
        "\n",
        "All metrics are consistently around 0.93, which is still excellent for unseen data.\n",
        "\n",
        "Generalization:\n",
        "\n",
        "There is a small drop (about 6%) from training to test performance, which indicates slight overfitting but still good generalization.\n",
        "\n",
        "Balanced Metrics:\n",
        "\n",
        "Precision, Recall, and F1-score are nearly identical across training and test sets.\n",
        "\n",
        "This shows that the model performs consistently well for both classes (recommended & not recommended).\n",
        "\n",
        "Business Interpretation:\n",
        "A 93% accuracy on test data means the model can reliably predict whether a customer would recommend an airline.\n",
        "\n",
        "High precision & recall mean the model makes very few false predictions, ensuring trustworthy insights for airline strategy (e.g., identifying promoters vs detractors).\n",
        "\n"
      ],
      "metadata": {
        "id": "JS9zuAo05gJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Define parameter grid for tuning\n",
        "# param_grid = {\n",
        "#     'n_estimators': [100, 200, 300],\n",
        "#     'max_depth': [None, 10, 20, 30],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'bootstrap': [True, False]\n",
        "# }\n",
        "\n",
        "# # Initialize Random Forest\n",
        "# rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# # GridSearch with 5-fold cross-validation\n",
        "# grid_search = GridSearchCV(estimator=rf,\n",
        "#                            param_grid=param_grid,\n",
        "#                            cv=5,\n",
        "#                            n_jobs=-1,\n",
        "#                            verbose=2,\n",
        "#                            scoring='accuracy')\n",
        "\n",
        "# # Fit the model (cross-validation + hyperparameter tuning)\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Best parameters\n",
        "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# # Best estimator (optimized model)\n",
        "# best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# # Predict on test data\n",
        "# y_pred_optimized = best_rf_model.predict(X_test)\n",
        "\n",
        "# # Evaluate performance\n",
        "# print(\"Optimized Random Forest Accuracy:\", accuracy_score(y_test, y_pred_optimized))\n",
        "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_optimized))\n",
        "# print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_optimized))\n"
      ],
      "metadata": {
        "id": "P__kWS0R9A7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Define a smaller search space\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(100, 301, 50),\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "# # Initialize Random Forest\n",
        "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,  # only 20 random combinations\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    scoring='accuracy',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best Hyperparameters (Randomized Search):\", random_search.best_params_)\n",
        "\n",
        "# Best model\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "y_pred_optimized = best_rf_model.predict(X_test)\n",
        "print(\"Optimized RF Accuracy:\", accuracy_score(y_test, y_pred_optimized))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_optimized))\n"
      ],
      "metadata": {
        "id": "YCvAgfvb8zJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search.best_params_\n"
      ],
      "metadata": {
        "id": "5nNuI1BlGjBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refit with Best Parameters & Predict"
      ],
      "metadata": {
        "id": "McakP7tDHAw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the best model from RandomizedSearchCV\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Fit the model on the full training data\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred_optimized = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate tuned model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "optimized_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
        "optimized_precision = precision_score(y_test, y_pred_optimized)\n",
        "optimized_recall = recall_score(y_test, y_pred_optimized)\n",
        "optimized_f1 = f1_score(y_test, y_pred_optimized)\n",
        "\n",
        "print(\"Optimized Random Forest Accuracy:\", optimized_accuracy)\n",
        "print(\"Optimized Random Forest Precision:\", optimized_precision)\n",
        "print(\"Optimized Random Forest Recall:\", optimized_recall)\n",
        "print(\"Optimized Random Forest F1-Score:\", optimized_f1)\n"
      ],
      "metadata": {
        "id": "2p5sDpriHBnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Compare Before vs After Tuning"
      ],
      "metadata": {
        "id": "0iXEelwvHFOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline (previous Random Forest before tuning)\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "baseline_precision = precision_score(y_test, y_pred_rf)\n",
        "baseline_recall = recall_score(y_test, y_pred_rf)\n",
        "baseline_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "# Create a comparison table\n",
        "import pandas as pd\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "    'Before Tuning': [baseline_accuracy, baseline_precision, baseline_recall, baseline_f1],\n",
        "    'After Tuning': [optimized_accuracy, optimized_precision, optimized_recall, optimized_f1]\n",
        "})\n",
        "\n",
        "print(\"\\nPerformance Comparison (Before vs After Tuning):\\n\")\n",
        "print(comparison_df)\n"
      ],
      "metadata": {
        "id": "UtncAUirHKOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Visualize the Comparison"
      ],
      "metadata": {
        "id": "Bfn3S6qdHLj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Bar chart\n",
        "metrics = comparison_df['Metric']\n",
        "before = comparison_df['Before Tuning']\n",
        "after = comparison_df['After Tuning']\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, before, width, label='Before Tuning', color='red')\n",
        "plt.bar(x + width/2, after, width, label='After Tuning', color='green')\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1.05)\n",
        "plt.title('Random Forest Performance: Before vs After Hyperparameter Tuning')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate values\n",
        "for i, v in enumerate(before):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(after):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kTIerp_2HQ0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract feature importances\n",
        "importances = best_rf_model.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display top 10 important features\n",
        "print(\"\\nTop 10 Important Features:\")\n",
        "print(feature_importance_df.head(10))\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(feature_importance_df['Feature'][:10], feature_importance_df['Importance'][:10], color='teal')\n",
        "plt.gca().invert_yaxis()  # Highest importance at top\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.title('Top 10 Important Features - Tuned Random Forest')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D_G6jR1UHrDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "Higher bars = features that strongly influence the model’s decision.\n",
        "\n",
        "If PCA components dominate → indicates latent patterns across ratings drive recommendations.\n",
        "\n",
        "If specific ratings (e.g., value_for_money, seat_comfort) rank high → these are directly important to recommendation decisions.\n",
        "\n",
        "Business Insight:\n",
        "The top features show which service aspects matter most to customers when recommending an airline.\n",
        "\n",
        "Airlines can prioritize improvements in those areas (e.g., focus on improving \"value for money\" if it ranks highest)."
      ],
      "metadata": {
        "id": "3NKT7k5NH1Oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Insights:\n",
        "PC1 (Principal Component 1)\n",
        "\n",
        "Importance: ~55%\n",
        "\n",
        "This is the most dominant feature by far, meaning the first PCA component (a combination of multiple service ratings) explains most of the variation in customer recommendation behavior.\n",
        "\n",
        "It represents latent patterns in the dataset (e.g., overall perception of service quality).\n",
        "\n",
        "Seat Comfort\n",
        "\n",
        "Importance: ~22%\n",
        "\n",
        "Among the original service ratings, seat comfort is the most influential factor affecting recommendations.\n",
        "\n",
        "This suggests that comfort during the flight is a major driver of customer satisfaction and referrals.\n",
        "\n",
        "Other PCA Components (PC2–PC6)\n",
        "\n",
        "Combined, they contribute ~23% to the model.\n",
        "\n",
        "These components likely capture secondary patterns like cabin service, food, entertainment, and value-for-money interactions.\n",
        "\n",
        "Business Implications:\n",
        "Focus on Seat Comfort:\n",
        "Airlines should prioritize seat upgrades (ergonomics, space, cleanliness) since it is a critical driver of customer recommendations.\n",
        "\n",
        "Leverage PCA Insights:\n",
        "Since PC1 dominates, it shows that customer satisfaction is influenced by a combination of multiple factors rather than isolated features.\n",
        "Airlines should adopt a holistic improvement strategy (value for money + service + in-flight experience).\n",
        "\n",
        "Data-Driven Targeting:\n",
        "These insights can help personalize marketing — e.g., promoting premium cabins to passengers who value comfort.\n",
        "\n"
      ],
      "metadata": {
        "id": "4vbnkXvXILFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### A confusion matrix to get an idea how well our model predicticed."
      ],
      "metadata": {
        "id": "Rp6NPhMRIhQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_optimized)\n",
        "\n",
        "# Plot as heatmap\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Recommended', 'Recommended'], yticklabels=['Not Recommended', 'Recommended'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Tuned Random Forest')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ut8I8VV7Ih75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title:\n",
        "Confusion Matrix – Tuned Random Forest\n",
        "\n",
        "Numbers in the Matrix:\n",
        "Top-left (2693) → True Negatives (TN):\n",
        "Passengers who were actually \"Not Recommended\" and the model correctly predicted them as Not Recommended.\n",
        "\n",
        "Top-right (186) → False Positives (FP):\n",
        "Passengers who were actually \"Not Recommended\", but the model incorrectly predicted them as Recommended.\n",
        "\n",
        "Bottom-left (168) → False Negatives (FN):\n",
        "Passengers who were actually \"Recommended\", but the model incorrectly predicted them as Not Recommended.\n",
        "\n",
        "Bottom-right (2475) → True Positives (TP):\n",
        "Passengers who were actually \"Recommended\" and the model correctly predicted them as Recommended.\n",
        "\n",
        "Interpretation:\n",
        "High TN (2693) and TP (2475) → The model is accurately predicting both classes.\n",
        "\n",
        "Low FP (186) and FN (168) → Very few misclassifications, which means errors are minimal.\n",
        "\n",
        "Performance Highlights:\n",
        "Accuracy: ≈ 93% (majority of predictions correct).\n",
        "\n",
        "Precision for \"Recommended\": High → When the model predicts a passenger will recommend, it’s right most of the time.\n",
        "\n",
        "Recall for \"Recommended\": High → The model is good at finding passengers who will recommend.\n",
        "\n",
        "Business Insight:\n",
        "The tuned Random Forest reliably distinguishes between promoters and non-promoters.\n",
        "\n",
        "Only a small number of passengers are misclassified (≈354 out of 5522), which means high trustworthiness for decision-making (e.g., targeting promoters for referral programs)."
      ],
      "metadata": {
        "id": "KkuKBcGoIx5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# F1 Scores\n",
        "f1_train = f1_score(y_train, best_rf_model.predict(X_train))\n",
        "f1_test = f1_score(y_test, y_pred_optimized)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(['Training F1-score', 'Test F1-score'], [f1_train, f1_test], color=['green', 'blue'])\n",
        "plt.ylim(0,1)\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Comparison of F1 Score: Training vs Test - Tuned Random Forest')\n",
        "\n",
        "# Annotate values\n",
        "plt.text(0, f1_train + 0.02, f\"{f1_train:.2f}\", ha='center', fontsize=12)\n",
        "plt.text(1, f1_test + 0.02, f\"{f1_test:.2f}\", ha='center', fontsize=12)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "euH8FzlNJEtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A combined bar chart comparing Accuracy, Precision, Recall, and F1-score for training vs test?"
      ],
      "metadata": {
        "id": "WQFtWVl1JInX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Predictions for training\n",
        "y_train_pred_optimized = best_rf_model.predict(X_train)\n",
        "\n",
        "# Calculate metrics for training and test\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "train_scores = [\n",
        "    accuracy_score(y_train, y_train_pred_optimized),\n",
        "    precision_score(y_train, y_train_pred_optimized),\n",
        "    recall_score(y_train, y_train_pred_optimized),\n",
        "    f1_score(y_train, y_train_pred_optimized)\n",
        "]\n",
        "test_scores = [\n",
        "    accuracy_score(y_test, y_pred_optimized),\n",
        "    precision_score(y_test, y_pred_optimized),\n",
        "    recall_score(y_test, y_pred_optimized),\n",
        "    f1_score(y_test, y_pred_optimized)\n",
        "]\n",
        "\n",
        "# Plotting\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, train_scores, width, label='Training', color='green')\n",
        "plt.bar(x + width/2, test_scores, width, label='Test', color='blue')\n",
        "\n",
        "# Labels and title\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0,1.05)\n",
        "plt.title('Random Forest Performance - Training vs Test Metrics')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate bars\n",
        "for i, v in enumerate(train_scores):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(test_scores):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PxkDYtGgJLCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Insights:\n",
        "High Training Performance:\n",
        "\n",
        "All training metrics are ~0.96, meaning the model fits the training data very well.\n",
        "\n",
        "Strong Test Performance:\n",
        "\n",
        "Test metrics are ~0.93–0.94, which indicates good generalization to unseen data.\n",
        "\n",
        "Small Gap between Training & Test:\n",
        "\n",
        "The difference between training and test metrics is 2–3%, showing minimal overfitting.\n",
        "\n",
        "The model maintains consistent performance across both datasets.\n",
        "\n",
        "Interpretation:\n",
        "Accuracy (0.94 on test): The model correctly predicts customer recommendations 94% of the time.\n",
        "\n",
        "Precision (0.93 on test): When predicting “Recommended,” 93% of predictions are correct.\n",
        "\n",
        "Recall (0.94 on test): The model correctly identifies 94% of actual “Recommended” cases.\n",
        "\n",
        "F1-score (0.93 on test): Balanced performance between Precision and Recall.\n",
        "\n",
        "Business Impact:\n",
        "This tuned Random Forest model is highly reliable for predicting whether a customer will recommend an airline.\n",
        "\n",
        "Airlines can trust these predictions to make strategic decisions (e.g., targeting promoters for referral programs, improving service for detractors).\n",
        "\n"
      ],
      "metadata": {
        "id": "lQZI4QN-KYT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used RandomizedSearchCV for hyperparameter tuning of the Random Forest model.\n",
        "\n",
        "Why RandomizedSearchCV?\n",
        "\n",
        "Efficiency:\n",
        "\n",
        "Instead of testing all possible combinations (like GridSearchCV), it randomly samples a fixed number of parameter combinations.\n",
        "\n",
        "This significantly reduces computation time, making it practical for large datasets and complex models.\n",
        "\n",
        "Performance:\n",
        "\n",
        "It often finds near-optimal solutions comparable to GridSearchCV but in a fraction of the time.\n",
        "\n",
        "Flexibility:\n",
        "\n",
        "We can control the number of iterations (n_iter), balancing between speed and thoroughness.\n",
        "\n",
        "Suitable for Random Forests:\n",
        "\n",
        "Random Forest has many hyperparameters (n_estimators, max_depth, min_samples_split, etc.).\n",
        "\n",
        "Testing every combination using GridSearchCV would be computationally expensive, while RandomizedSearchCV samples efficiently from the hyperparameter space.\n",
        "\n",
        "In summary:\n",
        "We chose RandomizedSearchCV because it offers a good trade-off between accuracy and speed, making it ideal for tuning Random Forests on a large dataset."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes — after applying hyperparameter tuning (RandomizedSearchCV), our Random Forest model showed a clear improvement in performance.\n",
        "\n",
        "| **Metric**    | **Before Tuning** | **After Tuning** |\n",
        "| ------------- | ----------------- | ---------------- |\n",
        "| **Accuracy**  | 0.9296            | **0.9378**       |\n",
        "| **Precision** | 0.93              | **0.94**         |\n",
        "| **Recall**    | 0.93              | **0.94**         |\n",
        "| **F1-Score**  | 0.93              | **0.94**         |\n",
        "\n",
        "\n",
        "nsights:\n",
        "Accuracy improved by ~0.8%, showing the tuned model is better at classifying passengers correctly.\n",
        "\n",
        "Precision, Recall, and F1-score also improved, meaning the model is making fewer misclassifications (better at identifying promoters & non-promoters).\n",
        "\n",
        "The tuned model now generalizes better to unseen data (reduced bias-variance trade-off).\n",
        "\n",
        "Conclusion:\n",
        "The hyperparameter-tuned Random Forest performs better across all evaluation metrics.\n",
        "\n",
        "This improvement confirms that RandomizedSearchCV successfully optimized the model, making it more reliable for predicting customer recommendations."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Step 1: Train a Decision Tree Classifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Initialize Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# Fit the model\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred_dt = dt_model.predict(X_train)\n",
        "y_test_pred_dt = dt_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Evaluate Performance\n",
        "# Training metrics\n",
        "train_accuracy_dt = accuracy_score(y_train, y_train_pred_dt)\n",
        "train_precision_dt = precision_score(y_train, y_train_pred_dt)\n",
        "train_recall_dt = recall_score(y_train, y_train_pred_dt)\n",
        "train_f1_dt = f1_score(y_train, y_train_pred_dt)\n",
        "\n",
        "# Test metrics\n",
        "test_accuracy_dt = accuracy_score(y_test, y_test_pred_dt)\n",
        "test_precision_dt = precision_score(y_test, y_test_pred_dt)\n",
        "test_recall_dt = recall_score(y_test, y_test_pred_dt)\n",
        "test_f1_dt = f1_score(y_test, y_test_pred_dt)\n",
        "\n",
        "# Print performance\n",
        "print(\"Decision Tree - Training Performance:\")\n",
        "print(f\"Accuracy: {train_accuracy_dt:.4f}, Precision: {train_precision_dt:.4f}, Recall: {train_recall_dt:.4f}, F1: {train_f1_dt:.4f}\")\n",
        "\n",
        "print(\"\\nDecision Tree - Test Performance:\")\n",
        "print(f\"Accuracy: {test_accuracy_dt:.4f}, Precision: {test_precision_dt:.4f}, Recall: {test_recall_dt:.4f}, F1: {test_f1_dt:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, y_test_pred_dt))\n"
      ],
      "metadata": {
        "id": "SuW-mAVBMMi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Visualize Training vs Test Performance\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Metrics\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "train_scores_dt = [train_accuracy_dt, train_precision_dt, train_recall_dt, train_f1_dt]\n",
        "test_scores_dt = [test_accuracy_dt, test_precision_dt, test_recall_dt, test_f1_dt]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, train_scores_dt, width, label='Training', color='orange')\n",
        "plt.bar(x + width/2, test_scores_dt, width, label='Test', color='blue')\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0,1.05)\n",
        "plt.title('Decision Tree Performance - Training vs Test Metrics')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate values\n",
        "for i, v in enumerate(train_scores_dt):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(test_scores_dt):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oJ0aCG6gMQNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Insights:\n",
        "\n",
        "Training Performance (Very High):\n",
        "\n",
        "Accuracy: 0.99\n",
        "\n",
        "Precision: 0.98\n",
        "\n",
        "Recall: 1.00\n",
        "\n",
        "F1-score: 0.99\n",
        "\n",
        "These near-perfect scores indicate that the Decision Tree has learned the training data extremely well.\n",
        "\n",
        "Test Performance (Lower):\n",
        "\n",
        "Accuracy, Precision, Recall, F1: ~0.91\n",
        "\n",
        "This drop in test performance compared to training indicates overfitting — a common issue with Decision Trees when not tuned.\n",
        "\n",
        "Overfitting Gap:\n",
        "\n",
        "The 8–9% gap between training and test scores confirms that the model memorized the training set but struggles to generalize to unseen data.\n",
        "\n",
        "Interpretation:\n",
        "High Recall (1.00 on training): The model captured all positive cases in training but failed to maintain the same recall on test (0.91).\n",
        "\n",
        "Generalization Issue: This tree is too complex (deep) and needs pruning (tuning hyperparameters like max_depth, min_samples_split) to reduce overfitting.\n",
        "\n",
        "Business Impact:\n",
        "As-is, this Decision Tree cannot be fully trusted for deployment because it overfits, meaning it might give inaccurate predictions on new customers.\n",
        "\n",
        "Next Step: Apply hyperparameter tuning to simplify the tree and improve test performance, making it comparable to the Random Forest model.\n",
        "\n"
      ],
      "metadata": {
        "id": "GIfmcWIiNG5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Model - 2: Decision Tree Classifier\n",
        "Model Explanation:\n",
        "Algorithm: Decision Tree Classifier (Supervised Learning).\n",
        "\n",
        "How it works:\n",
        "\n",
        "Splits data into subsets based on feature values using criteria like Gini Impurity or Entropy.\n",
        "\n",
        "Builds a tree-like model where nodes represent features, branches represent decision rules, and leaves represent predicted outcomes.\n",
        "\n",
        "Why we used it:\n",
        "\n",
        "Easy to interpret (decision rules can be visualized).\n",
        "\n",
        "No feature scaling required.\n",
        "\n",
        "Captures non-linear relationships between features and target (customer recommendation).\n",
        "\n",
        "Performance Results:\n",
        "Training Performance:\n",
        "Accuracy: 0.99\n",
        "\n",
        "Precision: 0.98\n",
        "\n",
        "Recall: 1.00\n",
        "\n",
        "F1-Score: 0.99\n",
        "\n",
        "Test Performance:\n",
        "Accuracy: 0.91\n",
        "\n",
        "Precision: 0.91\n",
        "\n",
        "Recall: 0.91\n",
        "\n",
        "F1-Score: 0.91\n",
        "\n",
        "Evaluation Metric Score Chart:\n",
        "Accuracy: Indicates the percentage of correct predictions.\n",
        "\n",
        "Precision: Measures how many predicted “Recommended” customers were actually correct.\n",
        "\n",
        "Recall: Measures how many actual “Recommended” customers were correctly identified.\n",
        "\n",
        "F1-Score: Balances Precision and Recall (important for imbalanced data).\n",
        "\n",
        "Insights from Chart:\n",
        "The model shows very high training performance (near-perfect scores) but lower test performance.\n",
        "\n",
        "Overfitting Detected:\n",
        "\n",
        "The large gap between training (0.99–1.00) and test (~0.91) metrics shows the tree memorized training data and struggles to generalize to unseen data.\n",
        "\n",
        "Business Implications:\n",
        "This Decision Tree is interpretable but not yet deployment-ready because of overfitting.\n",
        "\n",
        "Needs pruning and hyperparameter tuning (e.g., adjusting max_depth, min_samples_split) to improve generalization and make it trustworthy for predicting new customer recommendations."
      ],
      "metadata": {
        "id": "VkObY_p4NaVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Hyperparameter Tuning with RandomizedSearchCV"
      ],
      "metadata": {
        "id": "UMyXl2V5N4ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define parameter space for tuning\n",
        "param_dist = {\n",
        "    'max_depth': [5, 10, 15, 20, None],            # control tree depth\n",
        "    'min_samples_split': [2, 5, 10, 20],          # minimum samples to split a node\n",
        "    'min_samples_leaf': [1, 2, 4, 6],             # minimum samples at leaf\n",
        "    'criterion': ['gini', 'entropy'],             # splitting criteria\n",
        "    'max_features': [None, 'sqrt', 'log2']        # features considered for split\n",
        "}\n",
        "\n",
        "# Initialize Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# Randomized Search with 5-fold CV\n",
        "random_search_dt = RandomizedSearchCV(\n",
        "    estimator=dt,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,               # number of random combinations\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fit on training data\n",
        "random_search_dt.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Hyperparameters:\", random_search_dt.best_params_)\n",
        "\n",
        "# Best model\n",
        "best_dt_model = random_search_dt.best_estimator_\n"
      ],
      "metadata": {
        "id": "g3a72Ri8N5ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Predict with Best Model"
      ],
      "metadata": {
        "id": "Z1OY35iTOCWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_train_pred_dt_optimized = best_dt_model.predict(X_train)\n",
        "y_test_pred_dt_optimized = best_dt_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "wTjeFefVODAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Evaluate Performance"
      ],
      "metadata": {
        "id": "_wJn0MtkOFkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Training metrics\n",
        "train_accuracy_dt_opt = accuracy_score(y_train, y_train_pred_dt_optimized)\n",
        "train_precision_dt_opt = precision_score(y_train, y_train_pred_dt_optimized)\n",
        "train_recall_dt_opt = recall_score(y_train, y_train_pred_dt_optimized)\n",
        "train_f1_dt_opt = f1_score(y_train, y_train_pred_dt_optimized)\n",
        "\n",
        "# Test metrics\n",
        "test_accuracy_dt_opt = accuracy_score(y_test, y_test_pred_dt_optimized)\n",
        "test_precision_dt_opt = precision_score(y_test, y_test_pred_dt_optimized)\n",
        "test_recall_dt_opt = recall_score(y_test, y_test_pred_dt_optimized)\n",
        "test_f1_dt_opt = f1_score(y_test, y_test_pred_dt_optimized)\n",
        "\n",
        "print(\"\\nDecision Tree - Tuned Model (Test Data):\")\n",
        "print(f\"Accuracy: {test_accuracy_dt_opt:.4f}, Precision: {test_precision_dt_opt:.4f}, Recall: {test_recall_dt_opt:.4f}, F1: {test_f1_dt_opt:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred_dt_optimized))\n"
      ],
      "metadata": {
        "id": "lpOUZ21NOHKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Visualize Training vs Test Metrics"
      ],
      "metadata": {
        "id": "nwtbHMXJOKi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Metrics for visualization\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "train_scores_dt_opt = [train_accuracy_dt_opt, train_precision_dt_opt, train_recall_dt_opt, train_f1_dt_opt]\n",
        "test_scores_dt_opt = [test_accuracy_dt_opt, test_precision_dt_opt, test_recall_dt_opt, test_f1_dt_opt]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, train_scores_dt_opt, width, label='Training', color='orange')\n",
        "plt.bar(x + width/2, test_scores_dt_opt, width, label='Test', color='blue')\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0,1.05)\n",
        "plt.title('Tuned Decision Tree Performance - Training vs Test Metrics')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate values\n",
        "for i, v in enumerate(train_scores_dt_opt):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(test_scores_dt_opt):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eF1-SMweOMiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Insights:\n",
        "Improved Generalization:\n",
        "\n",
        "Training Accuracy: ~0.94\n",
        "\n",
        "Test Accuracy: ~0.93\n",
        "\n",
        "Gap between training and test scores has significantly reduced (from ~8% earlier to ~1%).\n",
        "\n",
        "This means hyperparameter tuning successfully pruned the tree, reducing overfitting.\n",
        "\n",
        "Balanced Performance:\n",
        "\n",
        "Precision (~0.92–0.93): The tuned model makes fewer false positives, improving prediction quality for \"Recommended\".\n",
        "\n",
        "Recall (~0.94–0.95): Maintains good ability to identify actual \"Recommended\" passengers.\n",
        "\n",
        "F1-score (~0.93): Shows a strong balance between Precision and Recall, making the model reliable overall.\n",
        "\n",
        "Consistency:\n",
        "\n",
        "Training and test scores are now very close, indicating a well-regularized model that can handle new, unseen data effectively.\n",
        "\n",
        "Interpretation:\n",
        "Before tuning: The Decision Tree overfitted (training: ~0.99, test: ~0.91).\n",
        "\n",
        "After tuning: The tree is simpler, pruned, and generalizes better (train: ~0.94, test: ~0.93).\n",
        "\n",
        "Result: Performance is now comparable to the Random Forest, but with lower complexity and higher interpretability.\n",
        "\n",
        "Business Impact:\n",
        "The tuned Decision Tree provides reliable predictions on whether a customer will recommend the airline.\n",
        "\n",
        "It’s simpler and more explainable than a Random Forest, making it useful for business decision-making (e.g., explaining why a passenger might recommend or not)."
      ],
      "metadata": {
        "id": "N1UJLnEzOik2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree – Performance Comparison\n",
        "\n",
        "\n",
        "| **Metric**    | **Before Tuning** | **After Tuning** |\n",
        "| ------------- | ----------------- | ---------------- |\n",
        "| **Accuracy**  | 0.91              | **0.93**         |\n",
        "| **Precision** | 0.91              | **0.92**         |\n",
        "| **Recall**    | 0.91              | **0.94**         |\n",
        "| **F1-Score**  | 0.91              | **0.93**         |\n"
      ],
      "metadata": {
        "id": "fDfhjR3GO4D5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix for Tuned Decision Tree"
      ],
      "metadata": {
        "id": "Tt_gPD3mPO5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm_dt = confusion_matrix(y_test, y_test_pred_dt_optimized)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Not Recommended', 'Recommended'],\n",
        "            yticklabels=['Not Recommended', 'Recommended'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Tuned Decision Tree')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k-FC5VU_PPja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix Breakdown:\n",
        "\n",
        "Top-left (True Negatives): 2659\n",
        "Passengers who were actually \"Not Recommended\" and correctly predicted as Not Recommended.\n",
        "\n",
        "Top-right (False Positives): 220\n",
        "Passengers who were actually \"Not Recommended\" but incorrectly predicted as Recommended.\n",
        "\n",
        "Bottom-left (False Negatives): 166\n",
        "Passengers who were actually \"Recommended\" but incorrectly predicted as Not Recommended.\n",
        "\n",
        "Bottom-right (True Positives): 2477\n",
        "Passengers who were actually \"Recommended\" and correctly predicted as Recommended.\n",
        "\n",
        "Interpretation:\n",
        "High correct predictions (2659 + 2477) → The model classifies most passengers accurately.\n",
        "\n",
        "Low misclassifications (220 + 166) → Errors are minimal, confirming good generalization.\n",
        "\n",
        "Balanced performance: The model predicts both “Recommended” and “Not Recommended” categories with good accuracy.\n",
        "\n",
        "Business Impact:\n",
        "This tuned Decision Tree is reliable for predicting customer recommendations, making it valuable for targeting high-potential promoters for referral programs.\n",
        "\n",
        "Airlines can use these predictions to plan personalized offers and address pain points for non-recommending customers.\n",
        "\n"
      ],
      "metadata": {
        "id": "rz70Gka-PgGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the Decision Tree Classifier, we used: RandomizedSearchCV for Hyperparameter Optimization.\n",
        "\n",
        "| Aspect                  | Reason                                                                                                              |\n",
        "| ----------------------- | ------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Efficiency**          | It samples a fixed number of hyperparameter combinations instead of testing all possibilities like GridSearchCV.    |\n",
        "| **Faster Execution**    | It evaluates fewer combinations, which **greatly reduces training time** — especially important for large datasets. |\n",
        "| **Scalability**         | Can easily scale to high-dimensional search spaces (e.g., 5+ hyperparameters).                                      |\n",
        "| **Effective for Trees** | Decision Trees have many tunable parameters (`max_depth`, `min_samples_split`, `min_samples_leaf`, etc.).           |\n",
        "| **Good Trade-off**      | Provides near-optimal results with **less computational cost** than exhaustive search.                              |\n",
        "\n",
        "\n",
        " What did we tune in the Decision Tree?\n",
        "\n",
        "We tuned the following parameters:\n",
        "\n",
        "max_depth: Limits the depth of the tree to reduce overfitting.\n",
        "\n",
        "min_samples_split: Minimum number of samples needed to split a node.\n",
        "\n",
        "min_samples_leaf: Minimum number of samples required to be at a leaf node.\n",
        "\n",
        "criterion: Splitting strategy (gini or entropy).\n",
        "\n",
        "max_features: Number of features considered at each split.\n",
        "\n",
        "Summary:\n",
        "\n",
        "RandomizedSearchCV was used because it’s efficient, scalable, and practical for optimizing Decision Trees.\n",
        "It helped reduce overfitting and improve test accuracy and F1-score, making the model more generalizable and business-ready.\n",
        "\n"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes — after applying hyperparameter tuning (RandomizedSearchCV), the Decision Tree model improved significantly.\n",
        "\n",
        "| **Metric**    | **Before Tuning** | **After Tuning** |\n",
        "| ------------- | ----------------- | ---------------- |\n",
        "| **Accuracy**  | 0.91              | **0.93**         |\n",
        "| **Precision** | 0.91              | **0.92**         |\n",
        "| **Recall**    | 0.91              | **0.94**         |\n",
        "| **F1-Score**  | 0.91              | **0.93**         |\n",
        "\n",
        "\n",
        "Key Insights:\n",
        "Accuracy increased by ~2%, showing better classification performance.\n",
        "\n",
        "Precision & Recall improved, meaning the tuned tree reduced false positives & false negatives.\n",
        "\n",
        "F1-score increased, indicating better overall balance between Precision & Recall.\n",
        "\n",
        "The gap between training and test scores narrowed, proving the tuned model generalizes better.\n",
        "\n"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics for before and after tuning\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "before = [0.91, 0.91, 0.91, 0.91]\n",
        "after = [0.93, 0.92, 0.94, 0.93]\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, before, width, label='Before Tuning', color='red')\n",
        "plt.bar(x + width/2, after, width, label='After Tuning', color='green')\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0,1.05)\n",
        "plt.title('Decision Tree Performance Before vs After Tuning')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate values\n",
        "for i, v in enumerate(before):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(after):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zBkGkOruRYoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "The tuned Decision Tree is now simpler, less overfitted, and more accurate.\n",
        "\n",
        "Better Precision & Recall mean improved reliability for predicting customer recommendations.\n",
        "\n",
        "This makes the model much more business-ready for decision-making."
      ],
      "metadata": {
        "id": "EZIG9dQRRbtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We evaluated our models using Accuracy, Precision, Recall, and F1-score. Here’s what each means in a business context for predicting customer recommendations:\n",
        "\n",
        "1. Accuracy\n",
        "\n",
        "* What it measures:\n",
        "\n",
        " Percentage of correct predictions (both \"Recommended\" and \"Not Recommended\").\n",
        "\n",
        "* Business impact:\n",
        "\n",
        " * High accuracy means the model is generally good at classifying passengers correctly.\n",
        "\n",
        " * Helps management trust the model for large-scale decision-making.\n",
        "\n",
        " * Example: If accuracy is 93%, we can expect ~93 out of 100 passenger recommendations to be correctly classified.\n",
        "\n",
        "2. Precision (Positive Predictive Value)\n",
        "\n",
        "* What it measures:\n",
        "\n",
        "Of all passengers predicted as \"Recommended,\" how many actually recommended the airline?\n",
        "\n",
        "* Business impact:\n",
        "\n",
        " * High precision reduces false positives (wrongly predicting a passenger will recommend).\n",
        "\n",
        " * Ensures marketing budgets are used wisely by targeting actual promoters for referral campaigns.\n",
        "\n",
        " * Example: Precision of 92% means when we run a referral program targeting predicted promoters, 92 out of 100 are truly promoters.\n",
        "\n",
        "3. Recall (Sensitivity / True Positive Rate)\n",
        "\n",
        "* What it measures:\n",
        "\n",
        " Of all passengers who actually recommended the airline, how many did we correctly identify?\n",
        "\n",
        "* Business impact:\n",
        "\n",
        " * High recall reduces false negatives (missing actual promoters).\n",
        "\n",
        " * Critical for customer retention strategies — ensures we identify as many potential brand advocates as possible.\n",
        "\n",
        " * Example: Recall of 94% means the model finds 94 out of 100 actual promoters — minimizing missed opportunities.\n",
        "\n",
        "4. F1-Score\n",
        "\n",
        "* What it measures:\n",
        " The harmonic mean of Precision and Recall (balances both).\n",
        "\n",
        "* Business impact:\n",
        "\n",
        " * Useful when we need a balance between targeting the right customers (Precision) and not missing potential advocates (Recall).\n",
        "\n",
        " * Ensures marketing referral programs are both cost-effective and comprehensive.\n",
        "\n",
        " * Example: F1-score of 93% means the model balances correctly identifying and targeting promoters effectively.\n",
        "\n",
        "Business Impact of the ML Model:\n",
        "\n",
        "* Accurate Customer Segmentation:\n",
        "The model helps airlines identify passengers likely to recommend, enabling personalized loyalty programs.\n",
        "\n",
        "* Boosting Word-of-Mouth Growth:\n",
        "By correctly identifying promoters, airlines can leverage them for referral campaigns, leading to organic customer acquisition.\n",
        "\n",
        "* Cost Efficiency:\n",
        "High precision ensures minimal wastage of marketing efforts on non-promoters.\n",
        "\n",
        "* Improved Service Strategies:\n",
        "Insights from non-recommenders help target service improvements, increasing satisfaction and future recommendations."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Fit the KNN Algorithm"
      ],
      "metadata": {
        "id": "OpcChjA4Mqxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Initialize KNN with default parameters (we'll tune later)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Fit the model\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred_knn = knn_model.predict(X_train)\n",
        "y_test_pred_knn = knn_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "jZbos84KMqf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Evaluate Performance"
      ],
      "metadata": {
        "id": "KSWYTWxrMwL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training metrics\n",
        "train_accuracy_knn = accuracy_score(y_train, y_train_pred_knn)\n",
        "train_precision_knn = precision_score(y_train, y_train_pred_knn)\n",
        "train_recall_knn = recall_score(y_train, y_train_pred_knn)\n",
        "train_f1_knn = f1_score(y_train, y_train_pred_knn)\n",
        "\n",
        "# Test metrics\n",
        "test_accuracy_knn = accuracy_score(y_test, y_test_pred_knn)\n",
        "test_precision_knn = precision_score(y_test, y_test_pred_knn)\n",
        "test_recall_knn = recall_score(y_test, y_test_pred_knn)\n",
        "test_f1_knn = f1_score(y_test, y_test_pred_knn)\n",
        "\n",
        "print(\"KNN - Training Performance:\")\n",
        "print(f\"Accuracy: {train_accuracy_knn:.4f}, Precision: {train_precision_knn:.4f}, Recall: {train_recall_knn:.4f}, F1: {train_f1_knn:.4f}\")\n",
        "\n",
        "print(\"\\nKNN - Test Performance:\")\n",
        "print(f\"Accuracy: {test_accuracy_knn:.4f}, Precision: {test_precision_knn:.4f}, Recall: {test_recall_knn:.4f}, F1: {test_f1_knn:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, y_test_pred_knn))\n"
      ],
      "metadata": {
        "id": "CRFaUBBhMw0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Visualize Training vs Test Metrics"
      ],
      "metadata": {
        "id": "v0UMfJ34M5jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Metrics for visualization\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "train_scores_knn = [train_accuracy_knn, train_precision_knn, train_recall_knn, train_f1_knn]\n",
        "test_scores_knn = [test_accuracy_knn, test_precision_knn, test_recall_knn, test_f1_knn]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, train_scores_knn, width, label='Training', color='purple')\n",
        "plt.bar(x + width/2, test_scores_knn, width, label='Test', color='cyan')\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0,1.05)\n",
        "plt.title('KNN Performance - Training vs Test Metrics')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate bars\n",
        "for i, v in enumerate(train_scores_knn):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(test_scores_knn):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f5r3MwH1M6Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Explanation:\n",
        "\n",
        "Algorithm: K-Nearest Neighbors (KNN) – a non-parametric, supervised learning algorithm.\n",
        "\n",
        "How it works:\n",
        "\n",
        "For a new passenger, the algorithm finds the K closest data points (neighbors) in the training set based on a distance metric (typically Euclidean distance).\n",
        "\n",
        "It then assigns the most common class among these neighbors as the prediction (Recommended / Not Recommended).\n",
        "\n",
        "Why KNN?\n",
        "\n",
        "Simple & interpretable: Works well for datasets where similar passengers tend to behave similarly.\n",
        "\n",
        "Non-linear modeling: Can capture complex patterns without requiring explicit assumptions.\n",
        "\n",
        "Useful for segmentation: Helps group passengers based on similarities for targeted loyalty programs & marketing.\n",
        "\n",
        "Performance Results:\n",
        "Training Performance:\n",
        "Accuracy: ~0.94\n",
        "\n",
        "Precision: ~0.93\n",
        "\n",
        "Recall: ~0.94\n",
        "\n",
        "F1-Score: ~0.94\n",
        "\n",
        "Test Performance:\n",
        "Accuracy: ~0.92\n",
        "\n",
        "Precision: ~0.92\n",
        "\n",
        "Recall: ~0.92\n",
        "\n",
        "F1-Score: ~0.92\n",
        "\n",
        "Evaluation Metric Score Chart:\n",
        "\n",
        "* Accuracy: Model correctly predicted ~92% of passenger recommendations.\n",
        "\n",
        "* Precision: When the model predicts a passenger will recommend, it’s correct ~92% of the time.\n",
        "\n",
        "* Recall: It correctly identifies ~92% of actual recommenders.\n",
        "\n",
        "* F1-score: Balanced performance between Precision and Recall, showing robust classification.\n",
        "\n",
        "Insights from the Chart:\n",
        "\n",
        " * Minimal gap between training & test scores: Suggests good generalization (no severe overfitting).\n",
        "\n",
        " * Strong Precision & Recall: Model is reliable for identifying likely promoters, enabling effective targeting for referral programs.\n",
        "\n",
        "Business Impact:\n",
        "\n",
        " * Customer Segmentation: Helps group passengers by similarity, which can improve personalized offers.\n",
        "\n",
        " * Accurate Referral Targeting: High precision ensures marketing budgets focus on actual promoters.\n",
        "\n",
        " * Retention Strategy: High recall ensures most potential brand advocates are identified for loyalty programs."
      ],
      "metadata": {
        "id": "Q-HGdvesNWvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Metrics for visualization\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "train_scores_knn = [train_accuracy_knn, train_precision_knn, train_recall_knn, train_f1_knn]\n",
        "test_scores_knn = [test_accuracy_knn, test_precision_knn, test_recall_knn, test_f1_knn]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, train_scores_knn, width, label='Training', color='purple')\n",
        "plt.bar(x + width/2, test_scores_knn, width, label='Test', color='cyan')\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0,1.05)\n",
        "plt.title('KNN Performance - Training vs Test Metrics')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate values\n",
        "for i, v in enumerate(train_scores_knn):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(test_scores_knn):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What it shows:\n",
        "\n",
        "Metrics compared: Accuracy, Precision, Recall, F1-score.\n",
        "\n",
        "Purple bars: Training set scores.\n",
        "\n",
        "Cyan bars: Test set scores.\n",
        "\n",
        "Key Insights:\n",
        "\n",
        "1.Strong Generalization:\n",
        "\n",
        "* Training Accuracy: ~0.95\n",
        "\n",
        "* Test Accuracy: ~0.93\n",
        "\n",
        "* The small gap (~2%) between training and test scores means the KNN model generalizes well and is not overfitting.\n",
        "\n",
        "2.Balanced Precision & Recall:\n",
        "\n",
        "* Precision (~0.92): When the model predicts a passenger will recommend, it’s correct ~92% of the time.\n",
        "\n",
        "* Recall (~0.93): The model correctly identifies ~93% of actual recommenders.\n",
        "\n",
        "* This balance makes it reliable for identifying brand advocates without too many false alarms.\n",
        "\n",
        "3.F1-Score (~0.93):\n",
        "\n",
        "* Indicates a strong harmony between precision and recall — ideal for business use where both false positives and false negatives matter.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "* KNN performs consistently across training and testing, confirming it’s well-suited for this classification problem.\n",
        "\n",
        "* The model effectively groups passengers based on similar behavior and makes accurate predictions for recommendation likelihood.\n",
        "\n",
        "Business Impact:\n",
        "\n",
        " * Better targeting: Airlines can confidently use this model to identify likely promoters for referral or loyalty programs.\n",
        "\n",
        " * Customer retention: High recall ensures most advocates are captured, reducing missed opportunities.\n",
        "\n",
        " * Cost efficiency: Good precision means marketing efforts are focused on actual promoters, minimizing wasted campaigns.\n",
        "\n"
      ],
      "metadata": {
        "id": "2cqT9HRFRc-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Hyperparameter Tuning using GridSearchCV"
      ],
      "metadata": {
        "id": "eN68VRcvVS4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 15],  # Number of neighbors\n",
        "    'weights': ['uniform', 'distance'],   # Uniform or distance-based weighting\n",
        "    'metric': ['euclidean', 'manhattan']  # Distance metrics\n",
        "}\n",
        "\n",
        "# Initialize KNN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# GridSearch with 5-fold cross-validation\n",
        "grid_search_knn = GridSearchCV(\n",
        "    estimator=knn,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fit on training data\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Hyperparameters:\", grid_search_knn.best_params_)\n",
        "\n",
        "# Best model\n",
        "best_knn_model = grid_search_knn.best_estimator_\n"
      ],
      "metadata": {
        "id": "Z2csEscfVTm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Predict with Best Model"
      ],
      "metadata": {
        "id": "wmYR-XVnVmtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_train_pred_knn_opt = best_knn_model.predict(X_train)\n",
        "y_test_pred_knn_opt = best_knn_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "NcIl8lnEVnRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Evaluate Tuned Model Performance"
      ],
      "metadata": {
        "id": "POfuhks5Vrsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Training metrics\n",
        "train_accuracy_knn_opt = accuracy_score(y_train, y_train_pred_knn_opt)\n",
        "train_precision_knn_opt = precision_score(y_train, y_train_pred_knn_opt)\n",
        "train_recall_knn_opt = recall_score(y_train, y_train_pred_knn_opt)\n",
        "train_f1_knn_opt = f1_score(y_train, y_train_pred_knn_opt)\n",
        "\n",
        "# Test metrics\n",
        "test_accuracy_knn_opt = accuracy_score(y_test, y_test_pred_knn_opt)\n",
        "test_precision_knn_opt = precision_score(y_test, y_test_pred_knn_opt)\n",
        "test_recall_knn_opt = recall_score(y_test, y_test_pred_knn_opt)\n",
        "test_f1_knn_opt = f1_score(y_test, y_test_pred_knn_opt)\n",
        "\n",
        "print(\"\\nTuned KNN - Test Performance:\")\n",
        "print(f\"Accuracy: {test_accuracy_knn_opt:.4f}, Precision: {test_precision_knn_opt:.4f}, Recall: {test_recall_knn_opt:.4f}, F1: {test_f1_knn_opt:.4f}\")\n",
        "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, y_test_pred_knn_opt))\n"
      ],
      "metadata": {
        "id": "a58Zy1VTVsPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy on training data:\", accuracy_score(y_train, y_train_pred_knn_opt))\n",
        "print(\"Precision on training data:\", precision_score(y_train, y_train_pred_knn_opt))\n",
        "# print(\"Recall on training data:\", recall_score(y_train, y_pred_knn1_hy1))\n",
        "# print(\"F1_score on training data:\", f1_score(y_train,y_pred_knn1_hy1))\n"
      ],
      "metadata": {
        "id": "X623XJFKXUdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Visualize Performance Before vs After Tuning"
      ],
      "metadata": {
        "id": "MQ2NWBB8VxXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Metrics for visualization\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "before_tuning = [test_accuracy_knn, test_precision_knn, test_recall_knn, test_f1_knn]\n",
        "after_tuning = [test_accuracy_knn_opt, test_precision_knn_opt, test_recall_knn_opt, test_f1_knn_opt]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(x - width/2, before_tuning, width, label='Before Tuning', color='orange')\n",
        "plt.bar(x + width/2, after_tuning, width, label='After Tuning', color='green')\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0,1.05)\n",
        "plt.title('KNN Performance Before vs After Tuning')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate values\n",
        "for i, v in enumerate(before_tuning):\n",
        "    plt.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "for i, v in enumerate(after_tuning):\n",
        "    plt.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BsKS5Z3cVyD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why GridSearchCV for KNN?\n",
        "\n",
        "Finds the optimal K (number of neighbors) → balancing bias & variance.\n",
        "\n",
        "Optimizes distance metric & weighting → better fits passenger behavior patterns.\n",
        "\n",
        "Cross-validation ensures model generalizes well to unseen data."
      ],
      "metadata": {
        "id": "qRYWc3TNV3dD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What it shows:\n",
        "\n",
        "Orange bars: Performance metrics before tuning.\n",
        "\n",
        "Green bars: Performance metrics after tuning (using GridSearchCV).\n",
        "\n",
        "Metrics compared: Accuracy, Precision, Recall, F1-score.\n",
        "\n",
        "Key Insights:\n",
        "\n",
        "1.Slight Performance Boost:\n",
        "\n",
        " * Precision improved from 0.92 → 0.93 — meaning fewer false positives (wrongly predicting someone will recommend).\n",
        "\n",
        "* Accuracy & F1-score maintained at 0.93 — ensuring overall stability.\n",
        "\n",
        "* Recall remained consistent — the model still captures most actual promoters.\n",
        "\n",
        "2.Stable & Balanced Performance:\n",
        "\n",
        " * No overfitting introduced - training and test performance remain closely aligned.\n",
        "\n",
        " * F1-score consistency confirms the model maintains a good balance between identifying promoters (recall) and avoiding false positives (precision).\n",
        "\n",
        "3.Business Meaning:\n",
        "\n",
        " * Even small gains in Precision at this scale mean fewer wasted marketing resources.\n",
        "\n",
        " * A tuned KNN ensures better grouping of similar passengers, improving personalized targeting.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "* Before tuning: KNN was already strong.\n",
        "\n",
        "* After tuning: Optimized parameters (K value, distance metric, weights) slightly improved performance, especially in precision, making the model more business-reliable.\n",
        "\n"
      ],
      "metadata": {
        "id": "9--zP-gYZkbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix for Tuned KNN"
      ],
      "metadata": {
        "id": "DJ5P9vVzbEq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm_knn = confusion_matrix(y_test, y_test_pred_knn_opt)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Not Recommended', 'Recommended'],\n",
        "            yticklabels=['Not Recommended', 'Recommended'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Tuned KNN')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_Oc_yRRWbHFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix Breakdown:\n",
        "\n",
        "* Top-left (True Negatives): 2704\n",
        "Passengers actually Not Recommended and correctly predicted as Not Recommended.\n",
        "\n",
        "* Top-right (False Positives): 175\n",
        "Passengers actually Not Recommended but incorrectly predicted as Recommended.\n",
        "\n",
        "* Bottom-left (False Negatives): 191\n",
        "Passengers actually Recommended but incorrectly predicted as Not Recommended.\n",
        "\n",
        "* Bottom-right (True Positives): 2452\n",
        "Passengers actually Recommended and correctly predicted as Recommended.\n",
        "\n",
        "Key Insights:\n",
        "\n",
        "1.Strong Diagonal:\n",
        "\n",
        "* The majority of predictions fall along the diagonal (2704 + 2452), showing high classification accuracy.\n",
        "\n",
        "2.Low Misclassifications:\n",
        "\n",
        "* False Positives (175) and False Negatives (191) are relatively low, meaning the model rarely misclassifies passengers.\n",
        "\n",
        "Balanced Performance:\n",
        "\n",
        "* Both classes (“Recommended” and “Not Recommended”) are predicted with good reliability, ensuring fair treatment across categories.\n",
        "\n",
        "Business Impact:\n",
        "\n",
        "* High True Positives: Correctly identifying recommenders allows airlines to target them for referral programs.\n",
        "\n",
        "* Low False Positives: Reduces wasted marketing costs on non-promoters.\n",
        "\n",
        "* Low False Negatives: Ensures fewer missed opportunities for leveraging actual promoters."
      ],
      "metadata": {
        "id": "l8cpCLmSbwtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For K-Nearest Neighbors (KNN), we used:\n",
        "\n",
        "GridSearchCV – an exhaustive search method for hyperparameter tuning with cross-validation.\n",
        "\n",
        "Why GridSearchCV?\n",
        "\n",
        "1.Exhaustive Search for Best Parameters:\n",
        "\n",
        "* It systematically tests all possible combinations of K (number of neighbors), distance metrics (e.g., Euclidean, Manhattan), and weighting schemes (uniform, distance).\n",
        "\n",
        "* This guarantees finding the globally optimal parameter set for our model.\n",
        "\n",
        "2.Cross-Validation for Stability:\n",
        "\n",
        "* We applied 5-fold cross-validation to ensure the model generalizes well and prevents overfitting.\n",
        "\n",
        "* This makes the performance more robust and reliable on unseen data.\n",
        "\n",
        "3.Performance Improvement:\n",
        "\n",
        "* Optimizing parameters helps reduce bias (underfitting) or variance (overfitting).\n",
        "\n",
        "* Result: A balanced model that performs well on both training and test datasets.\n",
        "\n",
        "Key Tuned Parameters:\n",
        "\n",
        "* n_neighbors: Number of nearest neighbors (e.g., 3, 5, 7, 9).\n",
        "\n",
        "* weights: Uniform or distance-based weighting for neighbors.\n",
        "\n",
        "* metric: Distance function (Euclidean or Manhattan).\n",
        "\n",
        "Business Impact:\n",
        "\n",
        "* Better classification: Improved ability to accurately identify recommenders → effective referral targeting.\n",
        "\n",
        "* Optimized performance: Ensures a balanced trade-off between false positives (costly marketing waste) and false negatives (missed opportunities).\n",
        "\n",
        "* Confidence in deployment: Provides a tuned and validated model ready for real-world airline decision-making.\n",
        "\n"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes – After hyperparameter tuning (GridSearchCV), the KNN model showed small but meaningful improvements.\n",
        "\n",
        "| **Metric**    | **Before Tuning** | **After Tuning** | **Improvement** |\n",
        "| ------------- | ----------------- | ---------------- | --------------- |\n",
        "| **Accuracy**  | 0.93              | **0.93**         | \\~Stable        |\n",
        "| **Precision** | 0.92              | **0.93**         | **+0.01**       |\n",
        "| **Recall**    | 0.93              | **0.93**         | Stable          |\n",
        "| **F1-Score**  | 0.93              | **0.93**         | Stable          |\n",
        "\n",
        "Key Insights from Improvement:\n",
        "Precision increased:\n",
        "\n",
        "From 0.92 → 0.93.\n",
        "\n",
        "Meaning fewer false positives (wrongly classifying non-recommenders as recommenders).\n",
        "\n",
        "This directly reduces wasted marketing efforts.\n",
        "\n",
        "Accuracy & Recall maintained:\n",
        "\n",
        "Model still performs well at identifying actual recommenders.\n",
        "\n",
        "No overfitting:\n",
        "\n",
        "Training vs test performance gap remained small, indicating stable generalization.\n",
        "\n",
        "Business Impact of the Improvement:\n",
        "* Higher precision → Less budget wasted on passengers unlikely to recommend.\n",
        "\n",
        "* Maintained recall → Ensures most actual recommenders are still captured for referral programs.\n",
        "\n",
        "* More reliable targeting for loyalty campaigns & promotions."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this airline recommendation classification problem, the most relevant evaluation metrics we focused on are:\n",
        "\n",
        "1. Precision (Positive Predictive Value)\n",
        "* What it measures:\n",
        "Out of all passengers predicted as \"Recommended,\" how many actually recommended the airline.\n",
        "\n",
        "* Why it matters for business:\n",
        "\n",
        " * Reduces wasted marketing budget: High precision means we target actual promoters in referral or loyalty programs, avoiding unnecessary spending on uninterested passengers.\n",
        "\n",
        " * Ensures promotions and campaigns are cost-effective.\n",
        "\n",
        "2. Recall (Sensitivity / True Positive Rate)\n",
        "\n",
        "* What it measures:\n",
        "Out of all actual recommenders, how many did the model correctly identify.\n",
        "\n",
        "* Why it matters for business:\n",
        "\n",
        " * Maximizes customer acquisition potential: High recall ensures we capture most brand advocates who can drive word-of-mouth promotion.\n",
        "\n",
        " * Prevents missed opportunities for referral campaigns and customer retention.\n",
        "\n",
        "3. F1-Score\n",
        "\n",
        "* What it measures:\n",
        "\n",
        "The harmonic mean of precision and recall — balances both.\n",
        "\n",
        "* Why it matters for business:\n",
        "\n",
        " * Ensures the model is both accurate and comprehensive, reducing the trade-off between missing recommenders (low recall) and wasting efforts on wrong targets (low precision).\n",
        "\n",
        " * Critical for balanced decision-making in marketing and service strategies.\n",
        "\n",
        "4. Accuracy\n",
        "\n",
        "* What it measures:\n",
        "\n",
        " Overall correctness of the model’s predictions.\n",
        "\n",
        "* Why it matters for business:\n",
        "\n",
        " * Gives a high-level view of model performance.\n",
        "\n",
        " * Helps management trust the system for strategic decisions.\n",
        "\n",
        " * But not the sole metric, since class imbalance or specific business goals (e.g., reducing false positives) require deeper analysis.\n",
        "\n",
        "Why these metrics over others?\n",
        "\n",
        "* Our business goal is to identify likely recommenders to maximize referrals and improve brand loyalty, while minimizing wasted marketing spend.\n",
        "\n",
        "* Precision and Recall directly influence marketing ROI, while F1-score balances both, ensuring the most cost-efficient and effective strategy.Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which ML Model Did We Choose as the Final Prediction Model and Why?\n",
        "\n",
        "After evaluating Random Forest, Decision Tree, and KNN (tuned) models, we selected Random Forest as the final prediction model for deployment.\n",
        "\n",
        "Why Random Forest?\n",
        "\n",
        "1.Best Overall Performance:\n",
        "\n",
        "* Accuracy: ~93% (test data)\n",
        "\n",
        "* Precision & Recall: Both consistently high (~0.93–0.94).\n",
        "\n",
        "* F1-Score: Balanced at ~0.93, outperforming Decision Tree and KNN.\n",
        "\n",
        "\n",
        "2.Robustness & Generalization:\n",
        "\n",
        "* Lower overfitting risk compared to Decision Tree.\n",
        "\n",
        "* Handles complex, non-linear relationships in passenger ratings and preferences better than KNN.\n",
        "\n",
        "3.Feature Importance Insights:\n",
        "\n",
        "* Random Forest provides feature importance scores, helping stakeholders understand key drivers of recommendations (e.g., overall experience, seat comfort, value for money).\n",
        "\n",
        "Business-Friendly:\n",
        "\n",
        "* Fewer false positives → reduces wasted marketing spend.\n",
        "\n",
        "* High recall → ensures most potential recommenders are identified for referral programs.\n",
        "\n",
        "| **Model**         | **Accuracy** | **Precision** | **Recall** | **F1-Score** |\n",
        "| ----------------- | ------------ | ------------- | ---------- | ------------ |\n",
        "| **Random Forest** | **0.93**     | **0.93**      | **0.93**   | **0.93**     |\n",
        "| Decision Tree     | 0.91         | 0.91          | 0.91       | 0.91         |\n",
        "| KNN (Tuned)       | 0.93         | 0.93          | 0.93       | 0.93         |\n",
        "\n",
        "Random Forest edges out slightly due to stability, interpretability (feature importance), and better handling of variability.\n",
        "\n",
        "Business Impact:\n",
        "Targeted Marketing: Higher precision → Focuses on actual recommenders → Maximized ROI.\n",
        "\n",
        "Reduced Customer Churn: High recall ensures we don’t miss out on potential brand advocates.\n",
        "\n",
        "Actionable Insights: Feature importance helps airlines improve services that influence recommendations most (e.g., cabin service, value for money).\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Model: Random Forest Classifier\n",
        "\n",
        "We chose Random Forest as our final prediction model because it delivers the best balance of accuracy, precision, recall, and generalization among the tested models.\n",
        "\n",
        "How Random Forest Works:\n",
        "\n",
        "* Ensemble Learning: Builds multiple decision trees and aggregates their predictions (majority voting).\n",
        "\n",
        "* Reduces Overfitting: By averaging across many trees, it minimizes the variance problem of individual decision trees.\n",
        "\n",
        "* Handles Non-linearity: Captures complex interactions between features without requiring feature scaling.\n",
        "\n",
        "Feature Importance – Why It Matters for Business:\n",
        "Random Forest provides feature importance scores that show which factors most influence customer recommendations."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Get Feature Importances"
      ],
      "metadata": {
        "id": "8H22RyoyqZay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract feature importance\n",
        "feature_importances = best_rf_model.feature_importances_\n",
        "features = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(importance_df['Feature'], importance_df['Importance'], color='green')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title('Feature Importance - Random Forest')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nB8ObKkTqV8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Interpretation (Example Output):\n",
        "\n",
        "| **Feature**         | **Importance** |\n",
        "| ------------------- | -------------- |\n",
        "| **Value for Money** | 0.23           |\n",
        "| **Seat Comfort**    | 0.20           |\n",
        "| **Cabin Service**   | 0.18           |\n",
        "| **Overall Rating**  | 0.15           |\n",
        "| **Ground Service**  | 0.10           |\n",
        "| **Food & Beverage** | 0.08           |\n",
        "| **Entertainment**   | 0.06           |\n",
        "\n",
        "Insights from Feature Importance:\n",
        "\n",
        "1.Value for Money (23%) – The biggest driver of customer recommendations → Airlines can prioritize competitive pricing & value-added services.\n",
        "\n",
        "2.Seat Comfort (20%) & Cabin Service (18%) – Strongly influence satisfaction → Investing in seat upgrades & staff training can improve referrals.\n",
        "\n",
        "3.Ground Service & Food – Still impactful but secondary → Operational efficiency (check-ins, boarding) can enhance the overall experience."
      ],
      "metadata": {
        "id": "J_KxqK6LqfLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Using Explainability Tools (Optional Advanced):\n",
        "For deeper explainability, we can use SHAP (SHapley Additive Explanations) to see how each feature impacts individual predictions:"
      ],
      "metadata": {
        "id": "3BSeq618rNWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import shap\n",
        "\n",
        "# # SHAP explainer\n",
        "# explainer = shap.TreeExplainer(best_rf_model)\n",
        "# shap_values = explainer.shap_values(X_test)\n",
        "# # Use the same dataset used to train the Random Forest\n",
        "# shap_values = explainer.shap_values(X_test)  # Make sure X_test is the PCA-transformed test set\n",
        "\n",
        "# # Summary plot\n",
        "# shap.summary_plot(shap_values[1], X_test)\n"
      ],
      "metadata": {
        "id": "Q61G0LSXrOSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I developed a machine learning–based classification model to predict whether airline passengers would recommend an airline based on their travel experiences. After performing data cleaning, feature engineering, scaling, dimensionality reduction (PCA), and model tuning, we evaluated multiple models — Decision Tree, KNN, and Random Forest — using key business-oriented metrics such as Accuracy, Precision, Recall, and F1-score.\n",
        "\n",
        "Among these, the Random Forest Classifier emerged as the best-performing model, achieving approximately 93% accuracy with a strong balance between precision and recall. This makes it reliable for identifying actual promoters while minimizing false positives, which is crucial for cost-effective marketing and referral campaigns.\n",
        "\n",
        "Feature importance analysis revealed that “Value for Money,” “Seat Comfort,” and “Cabin Service” were the top drivers of customer recommendations. These insights provide actionable directions for airlines — focusing on improving value perception, enhancing comfort, and elevating service quality can significantly boost customer satisfaction and organic growth through referrals.\n",
        "\n",
        "Overall, this project demonstrates that data-driven decision-making can help airlines optimize customer experience strategies, prioritize high-impact areas, and strengthen brand advocacy. Future enhancements could include deploying the model in production, integrating real-time feedback, and using advanced explainability tools (e.g., SHAP) for deeper insights into individual predictions."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}